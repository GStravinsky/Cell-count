{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nj--vuNnPcau"
   },
   "source": [
    "### Loading libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GR39VACMP2qs"
   },
   "outputs": [],
   "source": [
    "# For Google Collab to choose a newer version of TensorFlow\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "viRYJG_VGXaQ"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2hed\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hdoB209pN1Ds",
    "outputId": "650be8b5-1144-4fbd-e4fb-f03ff2d6ffd8"
   },
   "outputs": [],
   "source": [
    "# tensorflow imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.python.keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.constraints import max_norm\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8Nk73FAegdK5",
    "outputId": "33cae2b2-e237-4a3d-cfd4-ca632d36512c"
   },
   "outputs": [],
   "source": [
    "# checkin if GPU is on\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Ij1Ko0LioMfx",
    "outputId": "0e581deb-f944-440c-8741-fe16ddc37dc7"
   },
   "outputs": [],
   "source": [
    "# GOOGLE COLLAB ONLY\n",
    "\n",
    "# For Google Collab to mount the drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "akyjGTCVGXaX"
   },
   "outputs": [],
   "source": [
    "# Import and preprare the data\n",
    "D = h5py.File('/content/drive/My Drive/breast.h5', 'r') \n",
    "X,Y,P = D['images'],np.array(D['counts']),np.array(D['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Plyk621tPca6"
   },
   "source": [
    "The challenge webpage indicates that the area equal to 16px of a border around the edges was not used to count the number of  lymphocytes. Thus, I have decided to trim this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4OWOWRxPca7"
   },
   "outputs": [],
   "source": [
    "# trimming the are of the images equal to 16px\n",
    "X = X[:,16:283,16:283,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdjmrTBtgmXI"
   },
   "outputs": [],
   "source": [
    "# GOOGLE COLLAB ONLY - I HAD ISSUES TO IMPORT DATA WITH GPU\n",
    "\n",
    "# For Google Collab only - h5py with GPU does not work\n",
    "#X = np.load('/content/drive/My Drive/Colab Notebooks/X_data.npy')\n",
    "#Y = np.load('/content/drive/My Drive/Colab Notebooks/Y_data.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfS5MX_2GXab",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Question 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxXYGQPsHgwc"
   },
   "source": [
    "### i) Data breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LOlisqe7PcbG"
   },
   "source": [
    "There are 5841 training examples and 1563 testing examples in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlWN1c_zGXac"
   },
   "outputs": [],
   "source": [
    "# number of train examples\n",
    "np.sum(P<14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iitHcgcnGXag",
    "outputId": "514d22a0-5666-416a-b483-266fbcebefa8"
   },
   "outputs": [],
   "source": [
    "# number of test examples\n",
    "np.sum(P>=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fL8_IKpiGXaj"
   },
   "source": [
    "### ii) Showing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hyDS_rz6GXal",
    "outputId": "da01a6e8-112d-4974-fa47-c239718fcf37"
   },
   "outputs": [],
   "source": [
    "# showing images\n",
    "for i in range(0,5): \n",
    "    plt.imshow(X[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1MF8zPggGXao",
    "outputId": "4ed36463-2384-4773-ff1f-066f4618d897"
   },
   "outputs": [],
   "source": [
    "# Seeing respective count values\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYR6ex7zPcbX"
   },
   "source": [
    "The images show tissue with brown and blue cells on a light background. The brown cells are the cells of interest, however, how \"easy\" it is to count them varies. For example, the last image on display clearly shows that there are 6 lymphocytes whilst all the other images on display portray more ambiguous cases. It seems that the medical specialists were only counting the big and rather bold cells ignoring the small and bright ones. However, as the penultimate image with count 5 shows, this might not be a strong rule.\n",
    "\n",
    "Furthermore, the challenge creators have added zero counts images into the dataset too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "ytr1wYL_Ebz3",
    "outputId": "ee9f6c7b-7d52-4c53-daa1-9a54e93fec75"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[21,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIKWcrqzElqb"
   },
   "source": [
    "This image, for the human eye, is very obviously different and has no brown cells. Yet, some slightly darker patterns within an image might make the differentiation between two types of images difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tC7drTpPcbY"
   },
   "source": [
    "### iii) Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "HX8Vs6tDGXas",
    "outputId": "d5cb421a-ff02-4117-eeba-b01ca6dcc207"
   },
   "outputs": [],
   "source": [
    "# crude histogram\n",
    "plt.hist(Y, color = \"sandybrown\")\n",
    "plt.title(\"Histogram of counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HAREja37Pcbd"
   },
   "source": [
    "The histogram above shows a strong right skew. This indicates that the majority of the values are resting within 0 to 10 cells as well as that there are some outliers which need to be investigated. To investigate the outliers, I first want to see how many of them there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wHycIfbnGXaz",
    "outputId": "1c39e206-aced-4928-c5f9-e2fd3374a941"
   },
   "outputs": [],
   "source": [
    "# how many big values - might impose a problem.\n",
    "np.sum(Y>40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T_C4jKAIPcbh",
    "outputId": "35004a7e-50b4-4f10-bb49-f2a592f1f213"
   },
   "outputs": [],
   "source": [
    "# are there any with more than 200?\n",
    "np.sum(Y>200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3CEXHZlPcbk"
   },
   "source": [
    "There are only 5 values which are larger than 40 and none of the values are larger than 200 (thus I will exclude larger than 200 bin from the histogram required). The required histogram is presented bellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "LGK_-Wn9GXa4",
    "outputId": "217416dd-c727-4200-a125-c6726b172727"
   },
   "outputs": [],
   "source": [
    "# histogram by the (roughly) required bins. (I know there are no >200)\n",
    "(histogram_counts, bins, _) = plt.hist(Y, bins = [0,1,6,11,21,51,201], color = \"sandybrown\")\n",
    "plt.title(\"Histogram of counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "SG9NHgTQGXa_",
    "outputId": "42449b2b-3118-47ee-93fc-6abd90ca102a"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(histogram_counts)\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RX93-irRPcbt"
   },
   "source": [
    "The majority of the values lie between 0 to 51. There is only one value greater than 51. I want to examine it closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XixK2TZnPcbu",
    "outputId": "30352ef8-f4b4-4244-e590-adc5bbf43170"
   },
   "outputs": [],
   "source": [
    "Y[Y>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkF39zOlPcbx"
   },
   "source": [
    "Only one image has a cell count of 70. This sounds like an enormous number and I want to check the image with this count. It is important because if this is a mistake and not a real count, it might influence the models too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "9j0tseVtPcby",
    "outputId": "87861b15-10b2-4cde-a6e5-2dc288f7e341"
   },
   "outputs": [],
   "source": [
    "print(np.where(Y==70))\n",
    "plt.imshow(X[2892])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJOjJFrjPcb5"
   },
   "source": [
    "This image truly has a lot of brown cells, thus I am leaving this observation untouched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXF038XaGXbE"
   },
   "source": [
    "### iv) Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TeyUEpUCPcb6"
   },
   "source": [
    "To save time and stop my RAMs from crashing I have decided to transform the pre-processed brown layer data to int8 format from the original float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rdBcuMhtPcb7",
    "outputId": "f3fb173f-b8bb-4d10-88dd-e2a9342c2ffd"
   },
   "outputs": [],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHJEHjM0GXbL"
   },
   "outputs": [],
   "source": [
    "hed_data = rgb2hed(X[:1000,:,:,:])[:,:,:,2]\n",
    "hed_data = (hed_data * 128).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJLqoi9SGXbO"
   },
   "outputs": [],
   "source": [
    "hed_data_2 = rgb2hed(X[1000:2000])[:,:,:,2]\n",
    "hed_data_2 = (hed_data_2 * 128).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHQaWNQfGXbR"
   },
   "outputs": [],
   "source": [
    "hed_data = np.vstack((hed_data, hed_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-BnfLgnGXbT"
   },
   "outputs": [],
   "source": [
    "hed_data_2 = rgb2hed(X[2000:3000])[:,:,:,2]\n",
    "hed_data_2 = (hed_data_2 * 128).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qsb7JnX2GXbW"
   },
   "outputs": [],
   "source": [
    "hed_data = np.vstack((hed_data, hed_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yw0pPKTIGXbY"
   },
   "outputs": [],
   "source": [
    "hed_data_2 = rgb2hed(X[3000:4000])[:,:,:,2]\n",
    "hed_data_2 = (hed_data_2 * 128).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go7_DO9XGXbc"
   },
   "outputs": [],
   "source": [
    "hed_data = np.vstack((hed_data, hed_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58YOsuBcGXbg"
   },
   "outputs": [],
   "source": [
    "hed_data_2 = rgb2hed(X[4000:5000])[:,:,:,2]\n",
    "hed_data_2 = (hed_data_2 * 128).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2jHuOCXGXbi"
   },
   "outputs": [],
   "source": [
    "hed_data = np.vstack((hed_data, hed_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIGJay2LGXbl"
   },
   "outputs": [],
   "source": [
    "hed_data_2 = rgb2hed(X[5000:6000])[:,:,:,2]\n",
    "hed_data_2 = (hed_data_2 * 128).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqv3LFSCAWBw"
   },
   "outputs": [],
   "source": [
    "hed_data = np.vstack((hed_data, hed_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxIU7C2aPccz"
   },
   "outputs": [],
   "source": [
    "hed_data_2 = rgb2hed(X[6000:])[:,:,:,2]\n",
    "hed_data_2 = (hed_data_2 * 128).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wp-yHm_BPcc4"
   },
   "outputs": [],
   "source": [
    "hed_data = np.vstack((hed_data, hed_data_2))\n",
    "del(hed_data_2)\n",
    "# saving data for later use\n",
    "np.save(\"hed_data\", hed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8NKuYt8Pcc6"
   },
   "source": [
    "Showing the pre-processed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "V4wX0zrjGXbn",
    "outputId": "c0b83054-e5d1-4e11-8a9c-3559c2cf4feb"
   },
   "outputs": [],
   "source": [
    "# showing the pre-processed images\n",
    "cmap_hema = LinearSegmentedColormap.from_list('mycmap', ['white', 'navy'])\n",
    "cmap_dab = LinearSegmentedColormap.from_list('mycmap', ['white', 'saddlebrown'])\n",
    "cmap_eosin = LinearSegmentedColormap.from_list('mycmap', ['darkviolet', 'white'])\n",
    "\n",
    "for i in range(0,3):\n",
    "  fig, axes = plt.subplots(1, 2, figsize=(7, 6), sharex=True, sharey=True)\n",
    "  ax = axes.ravel()\n",
    "  ax[0].imshow(X[i,])\n",
    "  ax[0].set_title(\"Original image\")\n",
    "\n",
    "  ax[1].imshow(hed_data[i,], cmap=cmap_dab)\n",
    "  ax[1].set_title(\"DAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gTovLhTHSp2"
   },
   "source": [
    "### v) Scatter Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFnfKdTHPcc-"
   },
   "source": [
    "Creating data for an average \"brownness\" scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yjy7n2aFPcc_"
   },
   "outputs": [],
   "source": [
    "average_brown = []\n",
    "for i in range(0, np.shape(hed_data)[0]):\n",
    "    average_brown.append(np.mean(hed_data[i]))\n",
    "    \n",
    "average_brown = np.asarray(average_brown)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "WDQMJO_OPcdG",
    "outputId": "47d4b3fe-7172-41e2-c4e6-0fa172a2bcf3"
   },
   "outputs": [],
   "source": [
    "plt.scatter(average_brown, Y, color = \"saddlebrown\")\n",
    "plt.title(\"Average brown vs cell count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NoXkJzVEPcdK"
   },
   "source": [
    "The scatter plot above shows a strong positive correlation. The higher the number of cells - the more \"brownness\" there is. When it comes to zero count data, we see that those images can roughly be of any degree of \"brownness\". This almost surely will be a problem and the models are likely to struggle to recognise zero count images. Furthermore, the scatter plot also indicates that this covariate might struggle with smaller count data. Looking into pictures, we see that the size of the brown cells varies, and if they are smaller it might appear that the image is less brown, but the count of the cells might, nonetheless, be non-zero. Hence, this is a problem and we need to look for additional covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lG3Qoj3zPcdM"
   },
   "source": [
    "### vi) Number of images per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkOW70ZwPcdN",
    "outputId": "6273dd16-9251-4314-da31-21e4caf17db7"
   },
   "outputs": [],
   "source": [
    "np.unique(P, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcRZ9_fCPcdR"
   },
   "source": [
    "The number of images per patient is not even, yet I do not think it is a problem. We are not looking into person specific problem, but instead, we want to develop a pipeline that could predict the number of cells given any image. We must not rely on the prior knowledge - the prior cell count of the person. If we were to include covariates such as age, gender, lifestyle, etc. to improve our analysis then the individual counts might be more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UD3gdJzKPcdT"
   },
   "source": [
    "### vii) Performance measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCNuDIKXPcdU"
   },
   "source": [
    "I have chosen MSE to be the performance measure for this problem. There are two reasons behind it. First, MSE is nicely differentiable. Since I will be implementing Multilayer Perceptron and Convolutional Neural Networks, having a loss function with an easy to compute gradient, can make the problem slightly easier to solve as opposed to using, for example, mean absolute error. Secondly, MSE does not assume that the error of 10 is twice as bad as the error of 5. Instead, it assumes the error of 10 is four times as bad as the error of 5. In this specific context of leukocytes count, where the result of an error could be a wrong treatment for a patient, I believe we need to penalize the errors harsher. Nonetheless, MSE has its flaws too. For example, the training data has some big outliers (cell counts of more than 40, 70, thus it is unlikely that the model will predict them very acurately. As a result, MSE would explode in the presence of such an error. In addition, MSE is not interpretable in the units of measure. Luckily, this is an easily solvable problem if we take the square root of MSE. Thus, for most of the problems, I will be reporting RMSE only, yet when I will be conducting neural networks, I will use MSE as a loss functions behind the scenes but report RMSE instead owing to its interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIwHKPq0PcdV",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QRWj_c-PcdX"
   },
   "source": [
    "### i) Extracting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cypUF-FNPcdY"
   },
   "source": [
    "### a. Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kax8K0pMPcdb"
   },
   "source": [
    "Initially, I start by extracting the average colour of all the layers. Average \"brownness\" has been extracted before in Question 1, thus I will not do it again here. I plot scatter plots of each measure below as well as report the correlation coefficients of each feature will the cell counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7ZSaR51Pcdd"
   },
   "outputs": [],
   "source": [
    "# average red\n",
    "average_red = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    average_red.append(np.mean(X[i,:,:,0]))\n",
    "    \n",
    "# transforming into array    \n",
    "average_red = np.asarray(average_red)    \n",
    "#np.save(\"average_red\", average_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsxoGGjRPcdg"
   },
   "outputs": [],
   "source": [
    "# average green\n",
    "average_green = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    average_green.append(np.mean(X[i,:,:,1]))\n",
    "# transforming into array     \n",
    "average_green = np.asarray(average_green)    \n",
    "#np.save(\"average_green\", average_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sF3BAqDmPcdk"
   },
   "outputs": [],
   "source": [
    "# average blue\n",
    "average_blue = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    average_blue.append(np.mean(X[i,:,:,2]))\n",
    "average_blue = np.asarray(average_blue)\n",
    "#np.save(\"average_blue\", average_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sYQqHYwwPcdr",
    "outputId": "0411e280-a55f-4a4c-8e42-dc9ad0b4fabd"
   },
   "outputs": [],
   "source": [
    "plt.scatter(average_red, Y, color=\"firebrick\")\n",
    "plt.title(\"Average red vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(average_green, Y, color=\"olivedrab\")\n",
    "plt.title(\"Average green vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(average_blue, Y, color=\"royalblue\")\n",
    "plt.title(\"Average blue vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(average_brown, Y, color=\"saddlebrown\")\n",
    "plt.title(\"Average brown ves cell count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ZaDJWtVMPcd0",
    "outputId": "36a3926d-a513-40a3-e779-c2c54c54dc91"
   },
   "outputs": [],
   "source": [
    "print(\"Browness and counts correlation:\", np.corrcoef(average_brown, Y)[0,1],\n",
    "     \"Blueness and counts correlation:\", np.corrcoef(average_blue, Y)[0,1],\n",
    "     \"Redness and counts correlation:\", np.corrcoef(average_red, Y)[0,1],\n",
    "    \"Greeness and counts correlation:\", np.corrcoef(average_green, Y)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nq3Cju3tPcd2"
   },
   "source": [
    "Brownness, as discussed before, seems like a reasonably good predictor. The correlation coefficient is larger in absolute terms than that of the other three channels. Apart from that, all the channels showed some degree of codependency with the cell counts with blueness being the strongest based on the correlation coefficient among the three RGB layers. This is expected considering that the blue cells are those which \"compete\" for space with the brown ones. Overall, I believe that all of these four measures are worth keeping in at least for the initial regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiAUft9WPcd3",
    "toc-hr-collapsed": false
   },
   "source": [
    "### b. Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-Ds_1atPcd4"
   },
   "source": [
    "For the variance, I complete the same analysis as I did for the average colour of a filter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDHbgwV6Pcd5"
   },
   "outputs": [],
   "source": [
    "variance_brown = []\n",
    "for i in range(0, np.shape(hed_data)[0]):\n",
    "    variance_brown.append(np.var(hed_data[i]))\n",
    "    \n",
    "variance_brown = np.asarray(variance_brown)\n",
    "#np.save(\"variance_brown\", variance_brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zwl21J9IPceA"
   },
   "outputs": [],
   "source": [
    "variance_red = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    variance_red.append(np.var(X[i,:,:,0]))\n",
    "    \n",
    "variance_red = np.asarray(variance_red)\n",
    "#np.save(\"variance_red\", variance_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-KgCg3dPceD"
   },
   "outputs": [],
   "source": [
    "variance_green = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    variance_green.append(np.var(X[i,:,:,1]))\n",
    "    \n",
    "variance_green = np.asarray(variance_green)\n",
    "#np.save(\"variance_green\", variance_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIT6D41yPceG"
   },
   "outputs": [],
   "source": [
    "variance_blue = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    variance_blue.append(np.var(X[i,:,:,2]))\n",
    "    \n",
    "variance_blue = np.asarray(variance_blue)\n",
    "#np.save(\"variance_blue\", variance_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mWQn4p-APceM",
    "outputId": "62d3e77f-1ff3-40ae-e00b-5c19ed2319e9"
   },
   "outputs": [],
   "source": [
    "plt.scatter(variance_red, Y, color=\"firebrick\")\n",
    "plt.title(\"Variance of red vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(variance_green, Y, color=\"olivedrab\")\n",
    "plt.title(\"Variance of green vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(variance_blue, Y, color=\"royalblue\")\n",
    "plt.title(\"Variance of blue vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(variance_brown, Y, color=\"saddlebrown\")\n",
    "plt.title(\"Variance of brown vs cell count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "EmCD2Ru6PceR",
    "outputId": "f06acfb5-88d1-4157-c136-4db6bd84fee5"
   },
   "outputs": [],
   "source": [
    "print(\"Variance of brown and counts correlation:\", np.corrcoef(variance_brown, Y)[0,1],\n",
    "     \"Variance of blue and counts correlation:\", np.corrcoef(variance_blue, Y)[0,1],\n",
    "     \"Variance of red and counts correlation:\", np.corrcoef(variance_red, Y)[0,1],\n",
    "    \"Variance of green and counts correlation:\", np.corrcoef(variance_green, Y)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWwYu2oxPceU"
   },
   "source": [
    "From the scatterplots, we can see that the variance feature is a worse predictor than the average shade. The issue is that the variance covers almost all possible value space for the zero count data exceeding that of the non-zero count data. Nonetheless, the variance of brownness was the strongest predictor followed by the blueness again. Green and red variances show correlation of 0.25 and 0.16 respectively, thus I consider oomitting these variables out of the regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PqsgNT1PceV"
   },
   "source": [
    "### c. Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LxgQSM5IPceW"
   },
   "source": [
    "As before, the calculation of entropy will be followed by the scatter plots and the correlation coefficient with the cell count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGqd0ooLPceX"
   },
   "outputs": [],
   "source": [
    "# entropy red\n",
    "entropy_red = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    # need to reshape the image to get a single value of entropy\n",
    "    entropy_red.append(entropy(np.reshape(X[i,:,:,0], (267*267, ))))\n",
    "    \n",
    "entropy_red = np.asarray(entropy_red)    \n",
    "#np.save(\"entropy_red\", entropy_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcC5j4NePceZ"
   },
   "outputs": [],
   "source": [
    "# entropy green\n",
    "entropy_green = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    # need to reshape the image to get a single value of entropy\n",
    "    entropy_green.append(entropy(np.reshape(X[i,:,:,1], (267*267, ))))\n",
    "    \n",
    "entropy_green = np.asarray(entropy_green)    \n",
    "#np.save(\"entropy_green\", entropy_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1uPwNGjVPcec"
   },
   "outputs": [],
   "source": [
    "# entropy blue\n",
    "entropy_blue = []\n",
    "for i in range(0, np.shape(X)[0]):\n",
    "    # need to reshape the image to get a single value of entropy\n",
    "    entropy_blue.append(entropy(np.reshape(X[i,:,:,2], (267*267, ))))\n",
    "    \n",
    "entropy_blue = np.asarray(entropy_blue)    \n",
    "#np.save(\"entropy_blue\", entropy_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc-DK6ezPcee"
   },
   "outputs": [],
   "source": [
    "# entropy brown\n",
    "entropy_brown = []\n",
    "for i in range(0, np.shape(hed_data)[0]):\n",
    "    # need to reshape the image to get a single value of entropy\n",
    "    entropy_brown.append(entropy(np.reshape(hed_data[i], (267*267, ))))\n",
    "    \n",
    "entropy_brown = np.asarray(entropy_brown)    \n",
    "#np.save(\"entropy_brown\", entropy_brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "z0-_-IvRPcef",
    "outputId": "1e6c2726-e08f-4105-ce82-d168fe5c7cb7"
   },
   "outputs": [],
   "source": [
    "plt.scatter(entropy_red, Y, color=\"firebrick\")\n",
    "plt.title(\"Red entropy vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(entropy_green, Y, color=\"olivedrab\")\n",
    "plt.title(\"Green entropy vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(entropy_blue, Y, color=\"royalblue\")\n",
    "plt.title(\"Blue entropy vs cell count\")\n",
    "plt.show()\n",
    "plt.scatter(entropy_brown, Y, color=\"saddlebrown\")\n",
    "plt.title(\"Brown entropy vs cell count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "aalvJQ-7Pceh",
    "outputId": "947893a6-eb45-4a45-813f-07e63a35183d"
   },
   "outputs": [],
   "source": [
    "print(\"Brown entropy and counts correlation:\", np.corrcoef(entropy_brown, Y)[0,1],\n",
    "     \"Blue entropy and counts correlation:\", np.corrcoef(entropy_blue, Y)[0,1],\n",
    "     \"Red entropy and counts correlation:\", np.corrcoef(entropy_red, Y)[0,1],\n",
    "    \"Green entropy and counts correlation:\", np.corrcoef(entropy_green, Y)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PcoFh8eUPcel"
   },
   "source": [
    "Entropy suffers from the same problem as the variance - zero counts cover all possible entropy value space. As before, the entropy of brown and blue channels are the best predictors for the cell count out of all the four channels. However, even then the correlation is not great with brown entropy achieving 0.456. Considering low correlation coefficients of red and green entropies, it might be best to exclude those variables from the regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yV2ARh-HPcel"
   },
   "source": [
    "### d. Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ex0dsoY6Pcem"
   },
   "source": [
    "Bellow, I am plotting histograms of each channel. I combine all RGB channels into one histogram because they are following very similar patterns. I only plot the histograms of some of the images trying to find those which show some differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "-Wu6BSslPcen",
    "outputId": "292f45d9-9cf4-4fff-f204-afa15f679893"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.reshape(X[2475,:,:,0], (267*267,1)), list(range(0,256, 20)), color = \"red\")\n",
    "plt.hist(np.reshape(X[2475,:,:,1], (267*267,1)), list(range(0,256, 20)), color = \"green\", alpha=0.8)\n",
    "plt.hist(np.reshape(X[2575,:,:,2], (267*267,1)), list(range(0,256, 20)), color = \"blue\", alpha=0.5)\n",
    "plt.title(\"2475th image's histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "UXDKB5-ePcep",
    "outputId": "26cf7267-593b-46e1-eea2-ff9bc4bd028c"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.reshape(hed_data[2475], (267*267,1)), bins = 20, color = \"brown\")\n",
    "plt.title(\"2457th image's brown histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApClYn9MPcer"
   },
   "source": [
    "This particular image is dominated by the blue and brown channels with the red and green being less important. This echoes the mean, variance and entropy results observed above.\n",
    "\n",
    "Now let's examine another image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "VIFFzmsQPces",
    "outputId": "b1f6a46a-e4f3-4b6c-9f83-29978af1496c"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.reshape(X[3000,:,:,0], (267*267,1)), bins = list(range(0,256, 20)), color = \"red\")\n",
    "plt.hist(np.reshape(X[3000,:,:,1], (267*267,1)), bins = list(range(0,256, 20)), color = \"green\", alpha=0.9)\n",
    "plt.hist(np.reshape(X[3000,:,:,2], (267*267,1)), bins = list(range(0,256, 20)), color = \"blue\", alpha=0.6)\n",
    "plt.title(\"3000th image's histograms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "g_u7R2EpPcev",
    "outputId": "114ea591-0a75-4bbc-efe7-3a035d045bde"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.reshape(hed_data[3000], (267*267,1)), bins = 20, color = \"brown\")\n",
    "plt.title(\"3000th image's brown histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-EVXH92UPcey"
   },
   "source": [
    "In this case, the RGB histograms are mostly overlapping - thus one of those channels should be enough for predicting the cell counts. On the other hand, the brown channel is different and offers an informative feature.\n",
    "\n",
    "Overall, I think there is enough evidence to discard the green and red channels' variances and entropies from the regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-wo4_8PPcez",
    "toc-hr-collapsed": true
   },
   "source": [
    "### e. PC decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03ciHBaHPce2"
   },
   "source": [
    "The Principle Component decomposition will be implemented separately for the training and testing data. This is because eigenvectors are formed on the whole data, not just single observations as was the case for all the above features.\n",
    "\n",
    "Initially, I will try to find only 5 PCs to examine whether those components are any informative. If they all prove to be informative, I will calculate more PCs. In addition, to save time I will use a subset of the training data to test how many components are needed and once that is decided, I will extract the needed number of principal components from the full training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MutqoB8QPce2"
   },
   "outputs": [],
   "source": [
    "# proof-of-concept for red channel\n",
    "pca_red = PCA(5, svd_solver='randomized')\n",
    "projected_red = pca_red.fit_transform(np.reshape(X[:1000,:,:,0],(1000, 267*267)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u-yq9DBXPce6",
    "outputId": "7ce0c7e2-0564-4355-a5f6-6b049dc0b767"
   },
   "outputs": [],
   "source": [
    "np.sum(pca_red.explained_variance_ratio_)\n",
    "# 5 PCs explain 32% of the variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1g62O5adPce-",
    "outputId": "3711326f-d0e5-4514-e2a6-051b3c2cad18"
   },
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    plt.scatter(projected_red[:, i], Y[:1000], edgecolor='none', alpha=0.9, color = \"firebrick\")\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel( 'Y')\n",
    "    plt.title(\"Red PCs  vs cell count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "wqDisTEYPcfA",
    "outputId": "9df4ecc9-ddbd-440f-a607-441dcc27bf60"
   },
   "outputs": [],
   "source": [
    "print(\"PC1 and counts correlation:\", np.corrcoef(projected_red[:,0], Y[:1000])[0,1],\n",
    "     \"PC2 and counts correlation:\", np.corrcoef(projected_red[:,1], Y[:1000])[0,1],\n",
    "    \"PC3 and counts correlation:\", np.corrcoef(projected_red[:,2], Y[:1000])[0,1],\n",
    "      \"PC4 and counts correlation:\", np.corrcoef(projected_red[:,3], Y[:1000])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xg16lw7WPcfC"
   },
   "source": [
    "From the scatter plots and the correlation coefficients, we see that only the first PC gives meaningful information with the correlation coefficient of the 2nd, 3rd, etc. PCs reaching less than 0.05 in absolute terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8b2Bq9CPcfC"
   },
   "outputs": [],
   "source": [
    "pca_green = PCA(5, svd_solver=\"randomized\")\n",
    "projected_green = pca_green.fit_transform(np.reshape(X[:1000,:,:,1],(1000, 267*267)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FKDiyoQmPcfD",
    "outputId": "6fa9472b-60c1-4e08-bc01-23178ccb2349"
   },
   "outputs": [],
   "source": [
    "np.sum(pca_green.explained_variance_ratio_)\n",
    "# 5 PCs explain 34% of a variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jlTeX-H7PcfG",
    "outputId": "bced6796-1925-4352-e70f-ca807cd26576"
   },
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    plt.scatter(projected_green[:, i], Y[:1000], edgecolor='none', alpha=0.9, color = \"olivedrab\")\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel( 'Y')\n",
    "    plt.title(\"Green PCs vs cell count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "KWb03-UOPcfJ",
    "outputId": "7ec6ca16-8b64-4517-de49-b5500e15c452"
   },
   "outputs": [],
   "source": [
    "print(\"PC1 and counts correlation:\", np.corrcoef(projected_green[:,0], Y[:1000])[0,1],\n",
    "     \"PC2 and counts correlation:\", np.corrcoef(projected_green[:,1], Y[:1000])[0,1],\n",
    "    \"PC3 and counts correlation:\", np.corrcoef(projected_green[:,2], Y[:1000])[0,1],\n",
    "      \"PC4 and counts correlation:\", np.corrcoef(projected_green[:,3], Y[:1000])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o60HP1RHPcfM"
   },
   "source": [
    "As in the red channel case, only the first principal component of the green channel seems to be informative of the cell count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "863o4N_pPcfN"
   },
   "outputs": [],
   "source": [
    "# blue channel PC\n",
    "pca_blue = PCA(5, svd_solver=\"randomized\")\n",
    "projected_blue = pca_blue.fit_transform(np.reshape(X[:1000,:,:,2],(1000, 267*267)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7TxLdSQnPcfP",
    "outputId": "b1f324e7-634e-485f-911d-2138bdfbe121"
   },
   "outputs": [],
   "source": [
    "np.sum(pca_blue.explained_variance_ratio_)\n",
    "# 5 PCs explain 39% of a variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RvPBqV_nPcfR",
    "outputId": "a03b7997-4af0-4c30-cbe3-5fbd903e3837"
   },
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    plt.scatter(projected_blue[:, i], Y[:1000], edgecolor='none', alpha=0.9, color = \"royalblue\")\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel('Y')\n",
    "    plt.title(\"Blue PCs vs cell count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "XVORCGCQPcfV",
    "outputId": "185ea87b-0a3e-42d3-e2d2-cd40f8d40f8d"
   },
   "outputs": [],
   "source": [
    "print(\"PC1 and counts correlation:\", np.corrcoef(projected_blue[:,0], Y[:1000])[0,1],\n",
    "     \"PC2 and counts correlation:\", np.corrcoef(projected_blue[:,1], Y[:1000])[0,1],\n",
    "    \"PC3 and counts correlation:\", np.corrcoef(projected_blue[:,2], Y[:1000])[0,1],\n",
    "      \"PC4 and counts correlation:\", np.corrcoef(projected_blue[:,3], Y[:1000])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSaH3XHmPcfZ"
   },
   "source": [
    "Although the blue channel is usually more informative than the red or green, this time, similar to the red and green case, only the first PC is important in explaining cell count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6OOXHKxPcfa"
   },
   "outputs": [],
   "source": [
    "pca_brown = PCA(5, svd_solver=\"randomized\")\n",
    "projected_brown = pca_brown.fit_transform(np.reshape(hed_data[:1000] ,(1000, 267*267)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8jY4tX5dPcfb",
    "outputId": "36088908-2a58-47b3-a065-1ff673eafce3"
   },
   "outputs": [],
   "source": [
    "np.sum(pca_brown.explained_variance_ratio_)\n",
    "# 5 PCs explain 41% of a variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bRpIom5QPcfe",
    "outputId": "01996b10-1fc6-45d9-ec14-cd18e4bd910e"
   },
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    plt.scatter(projected_brown[:, i], Y[:1000], edgecolor='none', alpha=0.9, color = \"saddlebrown\")\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel( 'Y')\n",
    "    plt.title(\"Brown PCs vs cell count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "QQwVfqMDPcfj",
    "outputId": "0df6541d-d028-431e-cb2a-3e49b9cca69c"
   },
   "outputs": [],
   "source": [
    "print(\"PC1 and counts correlation:\", np.corrcoef(projected_brown[:,0], Y[:1000])[0,1],\n",
    "     \"PC2 and counts correlation:\", np.corrcoef(projected_brown[:,1], Y[:1000])[0,1],\n",
    "    \"PC3 and counts correlation:\", np.corrcoef(projected_brown[:,2], Y[:1000])[0,1],\n",
    "      \"PC4 and counts correlation:\", np.corrcoef(projected_brown[:,3], Y[:1000])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzzAixxZPcfl"
   },
   "source": [
    "Brown channel also showed that only the first PC is informative in predicting the cell counts. Overall, only the first principal component of all the channels seem to be informative with the rest not being informative. This is because the first PCs explain over 20% variation with the rest explaining only a fraction. Furthermore, even though the shapes of RGB PC1 seem the same, their range on the PC1 axis is different. Thus I consider putting all the PC1s into the model. \n",
    "\n",
    "Now I will create vectors of PC1 for each channel. Separately for training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddDc_x2ePcfm"
   },
   "source": [
    "#### Extracting PC for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5a_bg99tPcfn"
   },
   "outputs": [],
   "source": [
    "# red channel\n",
    "pca_red_train = PCA(1, svd_solver='randomized')\n",
    "projected_red_train = pca_red_train.fit_transform(np.reshape(X[:5841,:,:,0],(5841, 267*267)))\n",
    "\n",
    "#np.save(\"projected_red_train\", projected_red_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "u0nrkTNxPcfq",
    "outputId": "bae0fa7b-5f5a-4a70-fb4c-b55d23da5e87"
   },
   "outputs": [],
   "source": [
    "print('Explained variance ratio', pca_red_train.explained_variance_ratio_)\n",
    "plt.scatter(projected_red_train, Y[:5841], alpha=0.9, color='firebrick')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel( 'Y')\n",
    "plt.title(\"Red PC1 vs cell count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ns427ZxKPcfs"
   },
   "outputs": [],
   "source": [
    "# green channel\n",
    "pca_green_train = PCA(1, svd_solver='randomized')\n",
    "projected_green_train = pca_green_train.fit_transform(np.reshape(X[:5841,:,:,1],(5841, 267*267)))\n",
    "\n",
    "#np.save(\"projected_green_train\", projected_green_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "H08jYMTjPcfu",
    "outputId": "4e7b4fa6-da19-4209-e780-e5f95250f97d"
   },
   "outputs": [],
   "source": [
    "print('Explained variance ratio', pca_green_train.explained_variance_ratio_)\n",
    "plt.scatter(projected_green_train, Y[:5841], alpha=0.9, color='olivedrab')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel( 'Y')\n",
    "plt.title(\"Green PC1 vs cell count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tn0bi7QHPcfx"
   },
   "outputs": [],
   "source": [
    "# blue channel\n",
    "pca_blue_train = PCA(1, svd_solver='randomized')\n",
    "projected_blue_train = pca_blue_train.fit_transform(np.reshape(X[:5841,:,:,2],(5841, 267*267)))\n",
    "\n",
    "# saving to save time in the future\n",
    "#np.save(\"projected_blue_train\", projected_blue_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "15lrpwPBPcfz",
    "outputId": "6db1754f-46dd-4386-dd5b-1f293263bd8c"
   },
   "outputs": [],
   "source": [
    "print('Explained variance ratio', pca_blue_train.explained_variance_ratio_)\n",
    "plt.scatter(projected_blue_train, Y[:5841], alpha=0.9, color='royalblue')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel( 'Cell count')\n",
    "plt.title(\"Blue PC1 vs cell count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IoR-qBioPcf0"
   },
   "outputs": [],
   "source": [
    "# Brown channel\n",
    "pca_brown_train = PCA(1, svd_solver='randomized')\n",
    "projected_brown_train = pca_brown_train.fit_transform(np.reshape(hed_data[:5841],(5841, 267*267)))\n",
    "\n",
    "#np.save(\"projected_brown_train\", projected_brown_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "kY0P8sGaPcf3",
    "outputId": "c3f0f962-cc22-4fa1-b7e4-cc39b102550d"
   },
   "outputs": [],
   "source": [
    "print(\"projected_brown_train\", pca_brown_train.explained_variance_ratio_)\n",
    "plt.scatter(projected_brown_train, Y[:5841], color = \"saddlebrown\", alpha = 0.9)\n",
    "plt.title(\"Brown channel projection\")\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel( 'Cell count')\n",
    "plt.title(\"Brown PC1 vs cell count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-vAaMWiPcf9"
   },
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOVAs5Y9Pcf-"
   },
   "source": [
    "Extracting PCs for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vwofg0pWPcf-",
    "outputId": "46cd06a0-c3bf-43bf-d599-b89de51be352"
   },
   "outputs": [],
   "source": [
    "# red channel\n",
    "pca_red_test = PCA(1, svd_solver='randomized')\n",
    "projected_red_test = pca_red_test.fit_transform(np.reshape(X[5841:,:,:,0],(1563, 267*267)))\n",
    "\n",
    "#np.save(\"projected_red_test\", projected_red_test)\n",
    "print( \"Explained variance ratio:\", pca_red_test.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IPLdHvm1PcgB",
    "outputId": "0a566c50-bb64-486e-e141-8d221257dce8"
   },
   "outputs": [],
   "source": [
    "# green channel\n",
    "pca_green_test = PCA(1, svd_solver='randomized')\n",
    "projected_green_test = pca_green_test.fit_transform(np.reshape(X[5841:,:,:,1],(1563, 267*267)))\n",
    "\n",
    "#np.save(\"projected_green_test\", projected_green_test)\n",
    "print( \"Explained variance ratio:\", pca_green_test.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "STyzctOVPcgD",
    "outputId": "93735a32-d79a-4ccb-9dec-226f985a9e13"
   },
   "outputs": [],
   "source": [
    "# blue channel\n",
    "pca_blue_test = PCA(1, svd_solver='randomized')\n",
    "projected_blue_test = pca_blue_test.fit_transform(np.reshape(X[5841:,:,:,2],(1563, 267*267)))\n",
    "\n",
    "#np.save(\"projected_blue_test\", projected_blue_test)\n",
    "print( \"Explained variance ratio:\", pca_blue_test.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QBj8o7vIPcgI",
    "outputId": "7657e9db-0ad4-4488-a92a-b83cd670e575"
   },
   "outputs": [],
   "source": [
    "# brown channel\n",
    "pca_brown_test = PCA(1, svd_solver='randomized')\n",
    "projected_brown_test = pca_brown_test.fit_transform(np.reshape(hed_data[5841:,:,:],(1563, 267*267)))\n",
    "\n",
    "#np.save(\"projected_brown_test\", projected_brown_test)\n",
    "print( \"Explained variance ratio:\", pca_brown_test.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rltbYN4mPcgJ"
   },
   "source": [
    "### f. My own features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_GLkK58PcgJ"
   },
   "source": [
    "From what I see, when there is a higher concentration of cells (blue and brown), the simple \"brownness\" can be insufficient because the brown cells in the picture vary in size. Thus, the feature does not capture the relative brownness. To help with this issue, alongside the other  variables, I think it is worth including a ratio of brown cells to blue cells. The blue cells can be extracted via Hematoxylin channel. Then taking the ratio of the \"brownness\" of the DAB channel to the \"blueness\" of the Hematoxylin channel could help to separate brown cells from blue ones and also indirectly inform about the size of the brown cells. \n",
    "\n",
    "I begin by preprocessing the images and extracting Hematoxylin channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dh57vnexPcgK"
   },
   "outputs": [],
   "source": [
    "# extracting Hematoxylin channel\n",
    "hed_blue = rgb2hed(X[:1000,:,:,:])[:,:,:,0]\n",
    "hed_blue = (hed_blue * 128).astype(\"int8\")\n",
    "\n",
    "hed_blue_2 = rgb2hed(X[1000:2000])[:,:,:,0]\n",
    "hed_blue_2 = (hed_blue_2 * 128).astype(\"int8\")\n",
    "\n",
    "hed_blue = np.vstack((hed_blue, hed_blue_2))\n",
    "\n",
    "hed_blue_2 = rgb2hed(X[2000:3000])[:,:,:,0]\n",
    "hed_blue_2 = (hed_blue_2 * 128).astype(\"int8\")\n",
    "\n",
    "hed_blue = np.vstack((hed_blue, hed_blue_2))\n",
    "\n",
    "hed_blue_2 = rgb2hed(X[3000:4000])[:,:,:,0]\n",
    "hed_blue_2 = (hed_blue_2 * 128).astype(\"int8\")\n",
    "\n",
    "hed_blue = np.vstack((hed_blue, hed_blue_2))\n",
    "\n",
    "hed_blue_2 = rgb2hed(X[4000:5000])[:,:,:,0]\n",
    "hed_blue_2 = (hed_blue_2 * 128).astype(\"int8\")\n",
    "\n",
    "hed_blue = np.vstack((hed_blue, hed_blue_2))\n",
    "\n",
    "hed_blue_2 = rgb2hed(X[5000:6000])[:,:,:,0]\n",
    "hed_blue_2 = (hed_blue_2 * 128).astype(\"int8\")\n",
    "\n",
    "hed_blue = np.vstack((hed_blue, hed_blue_2))\n",
    "\n",
    "hed_blue_2 = rgb2hed(X[6000:])[:,:,:,0]\n",
    "hed_blue_2 = (hed_blue_2 * 128).astype(\"int8\")\n",
    "\n",
    "hed_blue = np.vstack((hed_blue, hed_blue_2))\n",
    "del(hed_blue_2)\n",
    "#np.save(\"hed_blue\", hed_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUrRmCXbPcgL"
   },
   "outputs": [],
   "source": [
    "# calculating the brown/blue ratio\n",
    "\n",
    "ratio_brown_blue = []\n",
    "for i in range(0,np.shape(hed_blue)[0]):\n",
    "    ratio_brown_blue.append(np.mean(hed_data[i,:,:])/(np.mean(hed_blue[i,:,:])))\n",
    "np.save(\"ratio_brown_blue\", ratio_brown_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "HZug9WHxPcgM",
    "outputId": "b870edf8-d6d5-4517-8d12-355fd27007b5"
   },
   "outputs": [],
   "source": [
    "plt.scatter(ratio_brown_blue, Y, color = \"goldenrod\")\n",
    "plt.title(\"Brown/blue vs cell counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qLGtMtgEPcgO",
    "outputId": "97dd1650-1b63-4c69-9121-c9118a15366b"
   },
   "outputs": [],
   "source": [
    "print(\"Correlation between brown/blue and cell counts:\", np.corrcoef(ratio_brown_blue, Y)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0s_BmP0fPcgQ"
   },
   "source": [
    "It seems that this feature is a good predictor of the cell counts. It has in absolute terms higher than 50 correlation which is also supported by the scatter plot. In addition, it deals with zero counts slightly better than entropy and variance. Thus, the feature will be added to the regression among other variables.\n",
    "\n",
    "\n",
    "Another feature which would serve the same purpose as the ratio of brown to blue would be the difference between the brown and blue colours. I expect it to capture similar information as the ratio feature above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-I_I3MsZPcgQ"
   },
   "outputs": [],
   "source": [
    "# calculating difference between brown and blue\n",
    "difference_blue_brown = []\n",
    "for i in range(0,np.shape(hed_blue)[0]):\n",
    "    difference_blue_brown.append(np.mean(hed_blue[i,:,:] - (hed_data[i,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "bQGAOI1bPcgT",
    "outputId": "c4f794fa-9bc5-4aa1-878d-03b3f4d0072b"
   },
   "outputs": [],
   "source": [
    "plt.scatter(difference_blue_brown, Y, color = \"goldenrod\")\n",
    "plt.title(\"Blue-brown difference vs cell counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yRL-mWbDPcgX",
    "outputId": "b885ab07-d1d3-496c-82b3-1509c80d1b3c"
   },
   "outputs": [],
   "source": [
    "print(\"Correlation between brown/blue and cell counts:\", np.corrcoef(difference_blue_brown, Y)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u64LmJsl16UB"
   },
   "source": [
    "Unfortunately, this feature does not seem to be strong in explaining cell counts. The correlation of 0.29 is much less than that of the ratio (0.53). Thus, I will not include this feature in the initial regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teKxppLmPcgc",
    "toc-hr-collapsed": false
   },
   "source": [
    "## ii) Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zL4ziUftPcgd"
   },
   "source": [
    "I start by constructing a feature matrix with all the selected features: brown to blue ratio, all average colours, blue and brown variance as well as entropy and the first principal components of all the four channels. I have decided to use pandas so I could have a better look if all the data mergers I do work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzdQRA8HPcgd"
   },
   "outputs": [],
   "source": [
    "features_train = pd.concat([pd.DataFrame(projected_brown_train), \n",
    "                            pd.DataFrame(projected_green_train)],axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(projected_red_train)], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(projected_blue_train)], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(average_red[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(average_blue[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(average_green[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(average_brown[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(ratio_brown_blue[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(variance_blue[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(variance_brown[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(entropy_blue[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(entropy_brown[:5841])], axis = 1)\n",
    "\n",
    "features_train = features_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HOU3X0wJPcgh",
    "outputId": "cd074561-235c-47b5-a402-fb65b134875c"
   },
   "outputs": [],
   "source": [
    "np.shape(features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9yP1FbdPcgm"
   },
   "source": [
    "For some models such as Support Vector Machine and Ridge Regression, it is best to standardize or normalize the data. This will be done later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgCEoL5DPcgp"
   },
   "source": [
    "### a. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N5JRXsiUPcgq"
   },
   "source": [
    "Before starting modelling, the cross-validation strategy must be set. The training data should not be validated and tested on the same patient's images since that might lead to model overperformance if it learns specific patterns of a specific patient. Thus, I have decided to manually create 3 folds: Fold 1 containing information from patients 1 to 4 (1935 cases), Fold 2 - patients from 5 to 10 (1949 cases) and Fold 3 - patients 11 to 13 (1957 cases). Consequently, the first training set will include Fold 2 and 3, second, fold 1 and 3 and third - fold 1 and 2. Leaving the remaining fold for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaMbfoUUPcgq"
   },
   "outputs": [],
   "source": [
    "# creating the function to split data into custom folds\n",
    "def Folds(X, Y):\n",
    "    val_1 = X[:1935]\n",
    "    val_2 = X[1935:3884]\n",
    "    val_3 = X[3884:]\n",
    "\n",
    "    val = [val_1, val_2, val_3]\n",
    "\n",
    "    val_1_labels = Y[:1935]\n",
    "    val_2_labels = Y[1935:3884]\n",
    "    val_3_labels = Y[3884:5841]\n",
    "\n",
    "    val_labels = [val_1_labels, val_2_labels, val_3_labels]\n",
    "\n",
    "    train_1 = np.vstack((val_2, val_3))\n",
    "    train_2 = np.vstack((val_1, val_3))\n",
    "    train_3 = np.vstack((val_1, val_2))\n",
    "\n",
    "    train = [train_1, train_2, train_3]\n",
    "\n",
    "    train_1_labels = np.hstack((val_2_labels, val_3_labels))\n",
    "    train_2_labels = np.hstack((val_1_labels, val_3_labels))\n",
    "    train_3_labels = np.hstack((val_1_labels, val_2_labels))\n",
    "\n",
    "    train_labels = [train_1_labels, train_2_labels, train_3_labels]\n",
    "    \n",
    "    return train, train_labels, val, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZDZ-NP1uPcgr"
   },
   "outputs": [],
   "source": [
    "train, train_labels, val, val_labels = Folds(features_train, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "esjlqbdqPcgs"
   },
   "source": [
    "Now we can run an initial regression with 13 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "TOxVUyuePcgt",
    "outputId": "cff793ac-f6d6-46c9-b8a6-5f3fa30ff214"
   },
   "outputs": [],
   "source": [
    "# creating lists to store the performance metrics\n",
    "RMSE = []\n",
    "R2 = []\n",
    "MAE = []\n",
    "CORR = []\n",
    "for i in range(0,3):\n",
    "    reg = sm.OLS(train_labels[i], train[i])\n",
    "    results = reg.fit()\n",
    "    \n",
    "    # the bellow if condition saves the summary table for all the folds so I could check the coeficient\n",
    "    # and their significance\n",
    "    if i == 0:\n",
    "        res_1 = results.summary()\n",
    "    elif i == 1:\n",
    "        res_2 = results.summary()\n",
    "    elif i == 2:\n",
    "        res_3 = results.summary()\n",
    "        \n",
    "    # Printing AIC score    \n",
    "    print(\"AIC:\", results.aic)\n",
    "    \n",
    "    # predictions on validation\n",
    "    reg_predict = results.predict(val[i])\n",
    "    MAE.append(mean_absolute_error(val_labels[i], reg_predict))\n",
    "    RMSE.append(mean_squared_error(val_labels[i], reg_predict, squared = False))  \n",
    "    R2.append(r2_score(val_labels[i], reg_predict))\n",
    "    CORR.append(np.corrcoef(val_labels[i], reg_predict)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hZB_yNbfPcgv",
    "outputId": "7168edb1-75c4-4924-f55f-16f610f056f7"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\", np.mean(RMSE), \"MAE:\", np.mean(MAE), \"R2:\",np.mean(R2), \"Correlation:\",np.mean(CORR))\n",
    "# RMSE: 2.935731077584135 MAE: 1.6943052652525477 R2: 0.5796665170172692 Correlation: 0.7741224780008006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "colab_type": "code",
    "id": "4otrMiGNPcgx",
    "outputId": "e298c656-c498-42e2-cf79-fe289cd01b3a"
   },
   "outputs": [],
   "source": [
    "res_1\n",
    "# looking into the summary of all the folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EZ4fCV9-Pcgz"
   },
   "source": [
    "The initial regression yielded reasonable results, yet their quality is best to be examined in the light of another model. Looking into the summary tables of all folds, green PC1 and average green seemed to be the most redundant variables, yet removing them did not improve the model based on AIC which means that the extra likelihood the variable gives fully balances out the penalty incurred with increasing model complexity. However, the RMSE went down to 2.8026. Nonetheless, when I have added extra variables in the next part of OLS analysis, the green entropy and variance appeared to be informative and improving the performance measures. Hence I decided to keep these two variables in. \n",
    "\n",
    "Note, the regression output signals about the multicollinearity issues, yet since our purpose is prediction, we can ignore that.\n",
    "\n",
    "\n",
    "As discussed above, I have decided to try out the before excluded variables in - green and red entropy as well as variance. The updated regression is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7HvmZwUvPcg4"
   },
   "outputs": [],
   "source": [
    "features_train = pd.concat([pd.DataFrame(features_train), pd.DataFrame(entropy_red[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(entropy_green[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(variance_red[:5841])], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(variance_green[:5841])], axis = 1)\n",
    "\n",
    "features_train = features_train.to_numpy()\n",
    "#np.save(\"features_train\", features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kpx7PcclPcg6",
    "outputId": "d13b50ef-3f37-4752-8214-af8b97585499"
   },
   "outputs": [],
   "source": [
    "np.shape(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyc1ojd2Pcg8"
   },
   "outputs": [],
   "source": [
    "train, train_labels, val, val_labels = Folds(features_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5EgeI0S7Pcg9",
    "outputId": "65ef9777-3aaf-47ee-c503-5a0b1416651d"
   },
   "outputs": [],
   "source": [
    "RMSE = []\n",
    "R2 = []\n",
    "MAE = []\n",
    "CORR = []\n",
    "for i in range(0,3):\n",
    "    reg = sm.OLS(train_labels[i], train[i])\n",
    "    results = reg.fit()\n",
    "    \n",
    "     # the bellow if condition saves the summary table for all the folds so I could check the coeficient\n",
    "    # and their significance\n",
    "    if i == 0:\n",
    "        res_1 = results.summary()\n",
    "    elif i == 1:\n",
    "        res_2 = results.summary()\n",
    "    elif i == 2:\n",
    "        res_3 = results.summary()\n",
    "        \n",
    "    # Printing AIC score    \n",
    "    print(\"AIC:\", results.aic)\n",
    "\n",
    "    # predictions on validation\n",
    "    reg_predict = results.predict(val[i])\n",
    "    MAE.append(mean_absolute_error(val_labels[i], reg_predict))\n",
    "    RMSE.append(mean_squared_error(val_labels[i], reg_predict, squared = False))  \n",
    "    R2.append(r2_score(val_labels[i], reg_predict))\n",
    "    CORR.append(np.corrcoef(val_labels[i], reg_predict)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlfmAXLvPcg-"
   },
   "source": [
    "AIC scores fell meaning that the likelihood of the data was improved even after penalizing the model complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ekGs813vPcg_",
    "outputId": "42327147-2bf5-45b8-b62e-c51543c72ba8"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\", np.mean(RMSE),\"MAE:\", np.mean(MAE), \"R2:\", np.mean(R2), \"Correlation:\", np.mean(CORR))\n",
    "# Much better. Look closer to coefficients\n",
    "#RMSE: 2.7500784188753076 MAE: 1.6472135884284327 R2: 0.6333676611925863 Correlation: 0.8213688088261231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XOppL0PPchC"
   },
   "source": [
    "This model yielded better results meaning that the extra variables were informative. RMSE fell by roughly 0.18, MAE by 0.04, R2 increased by 5 percentage points and the correlation by approximately 4.5. \n",
    "\n",
    "Now I examine the individual variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 751
    },
    "colab_type": "code",
    "id": "kOuDpVxJPchC",
    "outputId": "65413a93-4d98-4ef2-ef40-8d298162dbd0"
   },
   "outputs": [],
   "source": [
    "res_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbVN2d6wPchG"
   },
   "source": [
    "The significance of the variables is very sample dependent, thus I decided not to remove anything. I have also tried to add another feature I made - the difference between brown and blue - but it increased AIC and yielded worse validation performance measures. \n",
    "\n",
    "Another thing worth trying is to include quadratic terms of the Principal components variables. This is because looking at the PCs plots above, they all exhibit slightly quadratic shape, thus the quadratic components might help to employ the data better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wj8ghttPchG"
   },
   "outputs": [],
   "source": [
    "# adding quadratic PC variables to the dataset\n",
    "features_train = pd.concat([pd.DataFrame(features_train), pd.DataFrame(np.square(projected_brown_train[:5841]))], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(np.square(projected_red_train[:5841]))], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(np.square(projected_green_train[:5841]))], axis = 1)\n",
    "features_train = pd.concat([features_train, pd.DataFrame(np.square(projected_blue_train[:5841]))], axis = 1)\n",
    "\n",
    "features_train = features_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2RWn50_oPchO"
   },
   "outputs": [],
   "source": [
    "train, train_labels, val, val_labels = Folds(features_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "6qK7yUV_PchT",
    "outputId": "ff55dac6-984f-40f3-b869-76bee1ca81fd"
   },
   "outputs": [],
   "source": [
    "# Running the model again\n",
    "RMSE = []\n",
    "R2 = []\n",
    "MAE = []\n",
    "CORR = []\n",
    "for i in range(0,3):\n",
    "    reg = sm.OLS(train_labels[i], train[i])\n",
    "    results = reg.fit()\n",
    "    \n",
    "     # the bellow if condition saves the summary table for all the folds so I could check the coeficient\n",
    "    # and their significance\n",
    "    if i == 0:\n",
    "        res_1 = results.summary()\n",
    "    elif i == 1:\n",
    "        res_2 = results.summary()\n",
    "    elif i == 2:\n",
    "        res_3 = results.summary()\n",
    "        \n",
    "    # Printing AIC score    \n",
    "    print(\"AIC:\", results.aic)\n",
    "\n",
    "    # predictions on validation\n",
    "    reg_predict = results.predict(val[i])\n",
    "    MAE.append(mean_absolute_error(val_labels[i], reg_predict))\n",
    "    RMSE.append(mean_squared_error(val_labels[i], reg_predict, squared = False))  \n",
    "    R2.append(r2_score(val_labels[i], reg_predict))\n",
    "    CORR.append(np.corrcoef(val_labels[i], reg_predict)[0,1])\n",
    "# AIC is better    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ibO-Js6UPchV",
    "outputId": "5e5f038f-028b-4f13-cb69-0b85cca299bc"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\",np.mean(RMSE), \"MAE:\", np.mean(MAE), \"R2:\", np.mean(R2), \"Correlation\", np.mean(CORR))\n",
    "# Worse that without quadratic terms\n",
    "# RMSE: 2.8227556858033984 MAE: 1.691787904988676 R2: 0.6142554617774446 Correlation 0.8066181842408485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_G4iKhUPchW"
   },
   "source": [
    "Even though the quadratic variables improved AIC meaning that they increased the likelihood, the validation performance metrics appeared to be worse. This signals that the quadratic variables help to fit the model to the data better yet results in some degree of overfitting. Thus, for the testing, I have decided to use the data without these quadratic terms. \n",
    "\n",
    "Note, I have also tried standardizing and normalizing the data, yet the results appeared to be worse. Thus saving our time and space, I did not include this in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxHDJ2TxPchW"
   },
   "source": [
    "#### Testing OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8NUhXd3PchX"
   },
   "source": [
    "First, I will remove the quadratic terms from the training data, construct the test feature matrix, train the model on the whole data and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U_0O3GeQPchX",
    "outputId": "a72f533b-1e2d-4b1a-bd4d-59a564e0bd15"
   },
   "outputs": [],
   "source": [
    "# removing quadratic terms\n",
    "features_train = features_train[:,:17]\n",
    "np.shape(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYxTp-7UPchZ"
   },
   "outputs": [],
   "source": [
    "# Creating testing data\n",
    "features_test = pd.concat([pd.DataFrame(projected_brown_test), \n",
    "                            pd.DataFrame(projected_green_test)],axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(projected_red_test)], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(projected_blue_test)], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(average_red[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(average_blue[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(average_green[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(average_brown[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(ratio_brown_blue[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(variance_blue[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(variance_brown[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(entropy_blue[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(entropy_brown[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(entropy_red[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(entropy_green[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(variance_red[5841:])], axis = 1)\n",
    "features_test = pd.concat([features_test, pd.DataFrame(variance_green[5841:])], axis = 1)\n",
    "\n",
    "features_test = features_test.to_numpy()\n",
    "np.save(\"features_test\", features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T5zwVNPrPcha",
    "outputId": "7f1f1762-a274-4f87-8280-53dd73045790"
   },
   "outputs": [],
   "source": [
    "np.shape(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FbVvdaZNPchc",
    "outputId": "5f9a58dc-97dc-4486-f61a-f42a64ba8cce"
   },
   "outputs": [],
   "source": [
    "# training OLS based on the full training data\n",
    "reg_train = sm.OLS(Y[:5841], features_train)\n",
    "results = reg_train.fit()\n",
    "# predicting based on the testing data\n",
    "reg_predict_test = results.predict(features_test) \n",
    "print(\"AIC:\", results.aic)\n",
    "# AIC: 27311.223376278205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "HWY7p5cjPchi",
    "outputId": "e706e542-1cb7-4b7b-bb60-4665fbcac939"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\", mean_squared_error(Y[5841:], reg_predict_test, squared = False),\n",
    "      \"MAE:\", mean_absolute_error(Y[5841:], reg_predict_test),\n",
    "     \"R2:\", r2_score(Y[5841:], reg_predict_test),\n",
    "     \"Correlation:\", np.corrcoef(Y[5841:], reg_predict_test)[0,1])\n",
    "# RMSE: 4.588091148314126 MAE: 3.8287126314793585 R2: 0.19787807294349735 Correlation: 0.7920188573518981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "-O8RSHgBPchk",
    "outputId": "74cdbef7-a621-49e9-a5af-fc319c0b1f37"
   },
   "outputs": [],
   "source": [
    "# true against residuals plot\n",
    "plt.scatter(Y[5841:], (reg_predict_test - Y[5841:]) )\n",
    "plt.xlabel(\"True counts\")\n",
    "plt.ylabel(\"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9LfY94GPchm"
   },
   "source": [
    "Overall, the performance is not good and can only serve as a benchmark. From the scatter plot we can see that the biggest issue is with the zero counts as well as large counts. Whilst zero true counts are being overestimated, the large counts are being underestimated. Looking closer into the predicted counts' data, we can see that the model predicts negative counts for some observations. This is a big limitation of OLS and we better focus on the models which can prevent negative predictions from happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9D-vBHdPchn",
    "toc-hr-collapsed": false
   },
   "source": [
    "### Multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4Z1d2aJPchs"
   },
   "source": [
    "I have started with a multilayer perceptron having 2 hidden layers with a sigmoid activation function and a linear outer layer. I then compared the performance with ReLU and ReLU proved to be a superior network for this problem. I tried a few regularization methods - max norm, dropouts, batch normalization, L2 regularization. Since this MLP is a relatively small network, some of these regularization methods resulted in the over-regularization when the loss of the training data was consistently above that of the validation. I thus relaxed regularization and stayed with L2 regularization only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3SeBDwg1Pchs"
   },
   "source": [
    "I started running the network for 400 epochs and observed that the period where all of the folds perform the best is around the 100th epoch. At the epoch 150, some of the folds indicated validation set divergence. The loss function graphs are available bellow the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQBgxIcSPcht"
   },
   "outputs": [],
   "source": [
    "train, train_labels, val, val_labels = Folds(features_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F1f6C4MUPchu",
    "outputId": "ae61786c-c0a4-4bdf-bbf1-438d49f61782"
   },
   "outputs": [],
   "source": [
    "np.shape(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_2iCeVJqPchw",
    "outputId": "3fe6ac97-d424-421d-df45-efae263229a7"
   },
   "outputs": [],
   "source": [
    "# model 3 - ReLU model for 400 epochs\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(13,input_dim=np.shape(features_train)[1],\n",
    "                 kernel_initializer = 'uniform', activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(0.1)))\n",
    "model3.add(Dense(8,kernel_initializer = 'uniform', activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(0.1)))\n",
    "model3.add(Dense(4, kernel_initializer = 'uniform', activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.1)))\n",
    "model3.add(Dense(1,kernel_initializer = 'uniform', activation='relu'))\n",
    "model3.compile(loss = 'MSE',optimizer='adam',metrics=['MAE'])\n",
    "\n",
    "# using the same train/validation folds as in the OLS.\n",
    "for i in range(0,3):\n",
    "  if i == 0:\n",
    "    # creating checkpointer to store the results\n",
    "    checkpoint_path = \"training_1/3rd_model_1.ckpt\" \n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "    cp_model3 = ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only = True,\n",
    "                                monitor = 'val_loss')\n",
    "    history3_1 = model3.fit(train[i],train_labels[i], nb_epoch = 400, \n",
    "             batch_size = 32, callbacks = [cp_model3],\n",
    "             validation_data = (val[i], val_labels[i]))\n",
    "  elif i == 1:\n",
    "    # creating checkpointer to store the results\n",
    "    checkpoint_path = \"training_1/3rd_model_2.ckpt\"\n",
    "    heckpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "    cp_model3 = ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only = True,\n",
    "                                monitor = 'val_loss')\n",
    "    history3_2 = model3.fit(train[i], train_labels[i], nb_epoch = 400, \n",
    "             batch_size = 32, callbacks = [cp_model3],\n",
    "             validation_data = (val[i], val_labels[i]))\n",
    "  elif i == 2:\n",
    "    # creating checkpointer to store the results\n",
    "    checkpoint_path = \"training_1/3rd_model_3.ckpt\"\n",
    "    heckpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "    cp_model3 = ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only = True,\n",
    "                                monitor = 'val_loss')\n",
    "    history3_3 = model3.fit(train[i],train_labels[i], nb_epoch = 400, \n",
    "             batch_size = 32, callbacks = [cp_model3],\n",
    "             validation_data = (val[i], val_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "10XKTw6PPchx",
    "outputId": "8531fee0-1484-468c-c3e8-83975ef735e5"
   },
   "outputs": [],
   "source": [
    "# plotting validation vs testing loss function for the first fold\n",
    "plt.plot(history3_1.history['loss'][:])\n",
    "plt.plot(history3_1.history['val_loss'][:])\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "3cgUnA1YPchz",
    "outputId": "03f0e807-92d0-4f17-903e-4de4104e0427"
   },
   "outputs": [],
   "source": [
    "# plotting validation vs testing loss function for the second fold\n",
    "plt.plot(history3_2.history['loss'][:])\n",
    "plt.plot(history3_2.history['val_loss'][:])\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "mJZuY8Q7Pch0",
    "outputId": "60c8ad8f-2a7b-4349-821c-97b3c83abbcf"
   },
   "outputs": [],
   "source": [
    "# plotting validation vs testing loss function for the third fold\n",
    "plt.plot(history3_3.history['loss'][:])\n",
    "plt.plot(history3_3.history['val_loss'][:])\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XpHk8sQBPch4"
   },
   "source": [
    "Bellow, I will be running the network for 75 epochs for each fold. I have chosen a batch size of 36 because smaller batch sizes resulted in severe fluctuations of the loss curves which made it difficult to spot convergence and divergence. \n",
    "\n",
    "Besides, since the neural networks are stochastic, I ran the same neural network a few times to get a better look into the average performance of the model on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MJQmckPFPch5",
    "outputId": "cac917d6-1f1d-4551-912f-aea86d0b65dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reruning the network with 75 epochs\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(13,input_dim=np.shape(features_train)[1],\n",
    "                 kernel_initializer = 'uniform', activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(0.2)))\n",
    "model3.add(Dense(8,kernel_initializer = 'uniform', activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(0.2)))\n",
    "model3.add(Dense(4, kernel_initializer = 'uniform', activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.2)))\n",
    "model3.add(Dense(1,kernel_initializer = 'uniform', activation='relu'))\n",
    "model3.compile(loss = 'MSE',optimizer='adam',metrics=['MAE'])\n",
    "\n",
    "# creating lists to save validation results.\n",
    "RMSE_m3 = []\n",
    "MAE_m3 = []\n",
    "R2_m3 = []\n",
    "CORR_m3 = []\n",
    "\n",
    "# using the same train/validation folds as in the OLS.\n",
    "for i in range(0,3):\n",
    "  if i == 0:\n",
    "    # creating checkpointer to store the results\n",
    "    checkpoint_path = \"training_1/3rd_model_1.ckpt\" \n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "    cp_model3 = ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only = True, \n",
    "                                monitor = 'val_loss')\n",
    "    history3_1 = model3.fit(train[i],train_labels[i], nb_epoch = 75, \n",
    "             batch_size = 32, callbacks = [cp_model3],\n",
    "             validation_data = (val[i], val_labels[i]))\n",
    "  elif i == 1:\n",
    "    # creating checkpointer to store the results\n",
    "    checkpoint_path = \"training_1/3rd_model_2.ckpt\"\n",
    "    heckpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "    cp_model3 = ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only = True,\n",
    "                                monitor = 'val_loss')\n",
    "    history3_2 = model3.fit(train[i], train_labels[i], nb_epoch = 75, \n",
    "             batch_size = 32, callbacks = [cp_model3],\n",
    "             validation_data = (val[i], val_labels[i]))\n",
    "  elif i == 2:\n",
    "    # creating checkpointer to store the results\n",
    "    checkpoint_path = \"training_1/3rd_model_3.ckpt\"\n",
    "    heckpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "    cp_model3 = ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only = True,\n",
    "                                monitor = 'val_loss')\n",
    "    history3_3 = model3.fit(train[i],train_labels[i], nb_epoch = 75, \n",
    "             batch_size = 32, callbacks = [cp_model3],\n",
    "             validation_data = (val[i], val_labels[i]))\n",
    "\n",
    "  # getting validation predictions based on the last epochs weights for each fold\n",
    "  predicted = model3.predict(val[i])\n",
    "  RMSE_m3.append(mean_squared_error(val_labels[i], predicted, squared= False))   \n",
    "  MAE_m3.append(mean_absolute_error(val_labels[i], predicted))\n",
    "  R2_m3.append(r2_score(val_labels[i], predicted))  \n",
    "  CORR_m3.append(np.corrcoef(val_labels[i], np.reshape(predicted, (1, np.shape(predicted)[0])))[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "smQgPrtlPch7",
    "outputId": "c4d893a7-d8d6-466b-9954-472483ac0647"
   },
   "outputs": [],
   "source": [
    "# plotting validation vs testing loss function for the first fold\n",
    "plt.plot(history3_1.history['loss'][:])\n",
    "plt.plot(history3_1.history['val_loss'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "xJpodwi2PciD",
    "outputId": "e3cd3084-8d4c-4966-a1aa-7037ef3cf063"
   },
   "outputs": [],
   "source": [
    "# plotting validation vs testing loss function for the second fold\n",
    "plt.plot(history3_2.history['loss'][:])\n",
    "plt.plot(history3_2.history['val_loss'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "ZvZ1HGHyPciE",
    "outputId": "98a976ba-bca4-4a67-d323-a1e822fb9308"
   },
   "outputs": [],
   "source": [
    "# plotting validation vs testing loss function for the third fold\n",
    "plt.plot(history3_3.history['loss'][:])\n",
    "plt.plot(history3_3.history['val_loss'][:])\n",
    "# this folds must be easy, because for this fold only validation and testing loss curves overlap a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hsf47alaPciI"
   },
   "source": [
    "The first fold indicates the most  exemplary convergence whilst the second and third folds do not indicate a lot of learning. Looking into the graphs I believe this is the case because even with the initial weights, the networks generates a relatively low error (training RMSE of around 2 for both folds). Regarding the third fold where the validation loss is bellow that of training, it makes me conclude that the third validation set must be \"easy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eu4NJvY2PciI",
    "outputId": "be199fca-b43f-4950-d0c1-22cd07b97ff9"
   },
   "outputs": [],
   "source": [
    "print( \"RMSE:\", np.mean(RMSE_m3), \"MAE:\", np.mean(MAE_m3), \"R2:\", np.mean(R2_m3), \n",
    "      \"Correlation:\",np.mean(CORR_m3))\n",
    "\n",
    "# RMSE: 2.448540108099614 MAE: 1.3937737848963156 R2: 0.7086428615153176 Correlation: 0.8693118140748322\n",
    "# RMSE: 2.4865251758363804 MAE: 1.3799156730281288 R2: 0.6996322716447878 Correlation: 0.8715614647843276\n",
    "# RMSE: 2.1417990401852003 MAE: 1.2194835234270782 R2: 0.776113144433234 Correlation: 0.9069356959996351\n",
    "# RMSE: 2.1675515158649845 MAE: 1.3043220002001195 R2: 0.7720061203151826 Correlation: 0.8976773434131515\n",
    "# RMSE: 2.4062047717635333 MAE: 1.453062900701184 R2: 0.7101143472110184 Correlation: 0.8946536289511385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MmZhzuuPciJ"
   },
   "outputs": [],
   "source": [
    "m3_summary = np.array(\n",
    "[[ 2.448540108099614, 1.3937737848963156, 0.7086428615153176 ,0.8693118140748322],\n",
    "[2.4865251758363804 , 1.3799156730281288 , 0.6996322716447878 , 0.8715614647843276],\n",
    "[ 2.1417990401852003 ,1.2194835234270782 , 0.776113144433234 , 0.9069356959996351],\n",
    "[ 2.1675515158649845 , 1.3043220002001195 , 0.7720061203151826 ,0.8976773434131515],\n",
    "[ 2.4062047717635333 ,1.453062900701184 ,0.7101143472110184 ,0.8946536289511385]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "pEwBkUMjPciM",
    "outputId": "7e2b256f-c1f9-4f30-f7d1-02169ebd2e2c"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\", np.mean(m3_summary[:,0]), \"MAE:\", np.mean(m3_summary[:,1]), \n",
    "      \"R2:\", np.mean(m3_summary[:,2]), \"Correlation\", np.mean(m3_summary[:,3]))\n",
    "# RMSE: 2.3301241223499423 MAE: 1.3501115764505651 R2: 0.733301749023908 Correlation 0.888027989444617\n",
    "\n",
    "print(\"RMSE variance:\", np.var(m3_summary[:,0]), \"MAE variance:\", np.var(m3_summary[:,1]), \n",
    "      \"R2 variance:\", np.var(m3_summary[:,2]), \"Correlation variance\", np.var(m3_summary[:,3]))\n",
    "#RMSE variance: 0.021233617875919535 MAE variance: 0.00651080426280465 R2 variance: 0.0011220387953846586 \n",
    "#Correlation variance 0.00022319043058231704"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bjto0-ycPciP"
   },
   "source": [
    "Multilayer Perceptron definitely outperforms OLS at least on the validation set. RMSE decreased by on average 0.45, MAE fell by 0.32, R2 increased by 11 percentage points and correlation - by roughly 7. Variance remains relatively low and builds confidence in the results. \n",
    "\n",
    "Note, I have also tried to standardize and normalize the data for the MLP but the results appeared to be worse. For the same reason as before - saving your and my time - I will not include the analysis of the preprocessed data.\n",
    "\n",
    "Now, we need to see MLPs testing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6lZq9Z1kPciQ"
   },
   "source": [
    "#### Testing MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "w_87vGxbPciQ",
    "outputId": "1e69041e-aa0f-4b70-fb98-2ff16b36c65e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(13,input_dim=np.shape(features_train)[1],\n",
    "                 kernel_initializer = 'uniform', activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(0.2)))\n",
    "model3.add(Dense(8,kernel_initializer = 'uniform', activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(0.2)))\n",
    "model3.add(Dense(4, kernel_initializer = 'uniform', activation='relu',\n",
    "                kernel_regularizer=regularizers.l2(0.2)))\n",
    "model3.add(Dense(1,kernel_initializer = 'uniform', activation='relu'))\n",
    "model3.compile(loss = 'MSE',optimizer='adam',metrics=['MAE'])\n",
    "\n",
    "\n",
    "checkpoint_path = \"training_1/final_MLP.ckpt\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "cp_model3 = ModelCheckpoint(checkpoint_path, save_weights_only=True,  verbose=1,\n",
    "                              monitor = 'MSE')\n",
    "history_test = model3.fit(features_train,Y[:5841], nb_epoch = 75, batch_size = 32, \n",
    "                          callbacks = [cp_model3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFx1RTDAPciR",
    "outputId": "b348ed64-ad24-4e80-c51a-b3d8b120431b"
   },
   "outputs": [],
   "source": [
    "# plotting training loss function\n",
    "plt.plot(history_test.history['loss'])\n",
    "# steady and reasuring convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cibw5Ti_PciU",
    "outputId": "8526d96d-bf5f-4a67-da4b-8b900d593ef5"
   },
   "outputs": [],
   "source": [
    "# predicting based on the training set\n",
    "predictions_test = model3.predict(features_test)\n",
    "\n",
    "print(\"RMSE:\", mean_squared_error(Y[5841:], predictions_test, squared = False),\n",
    "      \"MAE:\", mean_absolute_error(Y[5841:], predictions_test),\n",
    "     \"R2:\", r2_score(Y[5841:], predictions_test),\n",
    "     \"Correlation:\", np.corrcoef(Y[5841:], np.reshape(predictions_test,\n",
    "                                                      (1, np.shape(predictions_test)[0])))[0,1])\n",
    "\n",
    "# RMSE: 2.6873412156480345 MAE: 1.39978451512978 R2: 0.7248167850851046 Correlation: 0.858725725571641\n",
    "# RMSE: 3.218160973821551 MAE: 1.6606015762170003 R2: 0.6053684147560368 Correlation: 0.8638262287048433\n",
    "# RMSE: 2.6120960289700195 MAE: 1.33473918143176 R2: 0.7400112283512154 Correlation: 0.868681345290561\n",
    "# RMSE: 3.0623111200234505 MAE: 1.5725380469039703 R2: 0.6426655094933946 Correlation: 0.8130529428367174\n",
    "# RMSE: 2.7921602825129033 MAE: 1.3609376257227082 R2: 0.7029312256022222 Correlation: 0.8455899133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wo2c6i2mPciZ"
   },
   "outputs": [],
   "source": [
    "m3_test_summary = np.array(\n",
    "[[ 2.6873412156480345 , 1.39978451512978 , 0.7248167850851046 , 0.858725725571641],\n",
    "[ 3.218160973821551 ,1.6606015762170003 , 0.6053684147560368 ,0.8638262287048433],\n",
    "[ 2.6120960289700195 , 1.33473918143176 , 0.7400112283512154 , 0.868681345290561],\n",
    "[ 3.0623111200234505 , 1.5725380469039703 ,0.6426655094933946 , 0.8130529428367174],\n",
    "[ 2.7921602825129033 , 1.3609376257227082 , 0.7029312256022222 , 0.8455899133]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "TJcWWJRyPcic",
    "outputId": "a95be417-5726-47b4-8827-c34c691a22cd"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\", np.mean(m3_test_summary[:,0]), \"MAE:\", np.mean(m3_test_summary[:,1]), \n",
    "      \"R2:\", np.mean(m3_test_summary[:,2]), \"Correlation\", np.mean(m3_test_summary[:,3]))\n",
    "# RMSE: 2.8744139241951916 MAE: 1.4657201890810438 R2: 0.6831586326575947 Correlation 0.8499752311407527\n",
    "\n",
    "print(\"RMSE variance:\", np.var(m3_test_summary[:,0]), \"MAE variance:\", np.var(m3_test_summary[:,1]), \n",
    "      \"R2 variance:\", np.var(m3_test_summary[:,2]), \"Correlation variance:\", np.var(m3_test_summary[:,3]))\n",
    "#RMSE variance: 0.05280798566709645 MAE variance: 0.016374346570017247 \n",
    "#R2 variance: 0.0026099171514585642 Correlation variance: 0.00040016527581236683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH5kh_R6Pcid"
   },
   "source": [
    "In testing data, MLP performs noticeably better than OLS. RMSE fell by 1.72, MAE fell by approximately 2,363, R2 rose by 48 percentage points and correlation rose by approximately 6 points. It is therefore sure, that MLP exploits the information from the extracted features much more efficiently than OLS. \n",
    "\n",
    "Nonetheless, MLP still makes an error which is on average equal to 1.5 counts (MAE). Whilst it is not a lot, it is good to examine which parts the network finds especially difficult. To do this, I plot residual versus true counts scatter plot below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "GocJz-ucPcid",
    "outputId": "1c9068d7-c7dd-498d-e18f-ea6da1fd91c5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# true counts vs residuals plot\n",
    "plt.scatter(Y[5841:], (np.reshape(predictions_test, (1, np.shape(predictions_test)[0])) - Y[5841:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YUxXasIPcie"
   },
   "source": [
    "Compared to OLS, MLP deals better with the zero counts data. This is because the model never predicts negative counts (due to the ReLU activation function which sets all negative values to zero). Overall, MLP works especially well for low to mid-range cell counts - the error is the smallest for the 0-10 cell count data. OLS struggled with low to mid-range counts too. Unfortunately, as with OLS, MLP struggles to accurately count the high cell data. From the scatter plot above, it seems that the model tends to underestimate the number of cells for the high count data. This suggests that we need to extract features which are characteristic to the high cell count data. Better examination of the images or CNN could help with this issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_9GZoUf6Pcif"
   },
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yp8V49iPcif"
   },
   "source": [
    "Ridge regression requires optimizing for the alpha parameters. Since I have custom folds, I will not use sklearn GridSearch but instead, write a barebones grid search to incorporate the custom folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMcZrXuqPcig"
   },
   "outputs": [],
   "source": [
    "# setting the parameter spaxe\n",
    "parameters_ridge = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "# empty list to incorporate the mean values across all three folds.\n",
    "RMSE_ridge = []\n",
    "\n",
    "for a in parameters_ridge:\n",
    "    # calling ridge regression\n",
    "    ridge = Ridge(a)\n",
    "    # list to hold RMSE scores of each fold - overritten each \"alpha\" loop\n",
    "    RMSE_temp = []\n",
    "    # loop against the 3 folds\n",
    "    for i in range(0,3):\n",
    "        ridge.fit(train[i], train_labels[i])\n",
    "        pred = ridge.predict(val[i])\n",
    "        RMSE_temp.append(mean_squared_error(val_labels[i], pred, squared = False))\n",
    "    # getting the mean accross all folds for each alpha parameter    \n",
    "    RMSE_ridge.append(np.mean(RMSE_temp))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ZalLAuGMPcij",
    "outputId": "441a3a73-7cce-4a5b-e1c0-997b5b2efad4"
   },
   "outputs": [],
   "source": [
    "RMSE_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n195krhWPcik"
   },
   "source": [
    "It seems that the alpha of 0.1 gives the highest validation performance indicating that less regularization is preferred. The RMSE score of 2.786 is slightly higher than the validation score achieved by OLS but this is expected due to the regularization. \n",
    "\n",
    "Ridge regression might benefit from the preprocessing and thus bellow I explore the effects of standardization and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AWZ4ywxPcik"
   },
   "outputs": [],
   "source": [
    "features_norm = preprocessing.normalize(features_train, norm=\"l2\")\n",
    "train, train_labels, val, val_labels = Folds(features_norm, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZXDBtMyOPcil"
   },
   "outputs": [],
   "source": [
    "# setting the parameter space\n",
    "parameters_ridge = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "# empty lis to incorporate the mean values across all three folds.\n",
    "RMSE_ridge = []\n",
    "\n",
    "for a in parameters_ridge:\n",
    "    # calling ridge regression\n",
    "    ridge = Ridge(a)\n",
    "    # list to hold RMSE scores of each fold - overritten each \"alpha\" loop\n",
    "    RMSE_temp = []\n",
    "    # loop against the 3 folds\n",
    "    for i in range(0,3):\n",
    "        ridge.fit(train[i], train_labels[i])\n",
    "        pred = ridge.predict(val[i])\n",
    "        RMSE_temp.append(mean_squared_error(val_labels[i], pred, squared = False))\n",
    "    # getting the mean accross all folds for each alpha parameter    \n",
    "    RMSE_ridge.append(np.mean(RMSE_temp))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "W0O94DI1Pcin",
    "outputId": "e11973a2-3d90-4c56-ffa0-72e394d4f504"
   },
   "outputs": [],
   "source": [
    "RMSE_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYlGNUtKPcio"
   },
   "source": [
    "Results with the normalized data are worse than with the un-processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJ8bhYcjPcip"
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "features_scale = scaler.fit_transform(features_train)\n",
    "train, train_labels, val, val_labels = Folds(features_scale, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wwk8jYTrPcir"
   },
   "outputs": [],
   "source": [
    "# setting the parameter space\n",
    "parameters_ridge = [0.1, 0.2 , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "# empty lis to incorporate the mean values across all three folds.\n",
    "RMSE_ridge = []\n",
    "\n",
    "for a in parameters_ridge:\n",
    "    # calling ridge regression\n",
    "    ridge = Ridge(a)\n",
    "    # list to hold RMSE scores of each fold - overritten each \"alpha\" loop\n",
    "    RMSE_temp = []\n",
    "    # loop against the 3 folds\n",
    "    for i in range(0,3):\n",
    "        ridge.fit(train[i], train_labels[i])\n",
    "        pred = ridge.predict(val[i])\n",
    "        RMSE_temp.append(mean_squared_error(val_labels[i], pred, squared = False))\n",
    "    # getting the mean accross all folds for each alpha parameter    \n",
    "    RMSE_ridge.append(np.mean(RMSE_temp))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ctaLyzbMPciu",
    "outputId": "3d981f17-d3d1-436e-c138-0b6e5185aeac"
   },
   "outputs": [],
   "source": [
    "RMSE_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fXM4K9XPciv"
   },
   "source": [
    "The results using standardized data are better than using normalized data, yet worse than using un-processed data. Thus, for the ridge regression, I have decided to use the un-processed data with alpha = 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsTRK2gMPciv"
   },
   "source": [
    "#### Testing Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0NIpvoBPciw"
   },
   "outputs": [],
   "source": [
    "ridge_test = Ridge(alpha = 0.1).fit(features_train, Y[:5841])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "DozMeOpYPcix",
    "outputId": "179245ee-c16b-437b-827b-07979551444f"
   },
   "outputs": [],
   "source": [
    "print(ridge_test.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2ms-69fPciy"
   },
   "outputs": [],
   "source": [
    "ridge_predict = ridge_test.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SCNbOKqqPci0",
    "outputId": "2eb243e2-e8b2-455b-eb52-3e26eb8efdc6"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\", mean_squared_error(Y[5841:], ridge_predict, squared = False),\n",
    "      \"MAE:\", mean_absolute_error(Y[5841:], ridge_predict),\n",
    "     \"R2:\", r2_score(Y[5841:], ridge_predict),\n",
    "      \"Correlation:\", np.corrcoef(Y[5841:], ridge_predict)[0,1])\n",
    "# RMSE: 3.776070401818422 MAE: 2.8368163257488477 R2: 0.45667901445475345 Correlation: 0.7989085675534381"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qA69hd3XPci2"
   },
   "source": [
    "First of all, Ridge regression yielded inferior results to MLP. When it comes to OLS, the regularization did manage to improve the results. RMSE fell by 0.81, MAE fell by roughly 1, R2 rose by approximately 25 percentage points whilst the correlation rose by a marginal 0.006. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "M6Nvyse5Pci3",
    "outputId": "70b19b04-cdcd-4e5a-8b9b-5cab74697656"
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y[5841:], (ridge_predict - Y[5841:]))\n",
    "plt.title(\"True counts vs residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uu9Fa2FoPci5"
   },
   "source": [
    "From the true counts vs predicted scatter plot, we can see that the model tends to underestimate the number of counts and deals with the zero counts worse than MLP. Thus MLP so far stands as the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KY5WzIX_Pci5"
   },
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9meibjt4Pci6"
   },
   "source": [
    "Support Vector Regression has a few parameters which need to be tuned in. For this reason, I will employ Grid Search. However, since I have custom training and testing folds, I will again write a barebones grid search to incorporate my folds. Furthermore, Support Vector Regression (especially RBF kernel and linear models with L2, L1 losses) usually assume that all features are standardized. Thus, I will preprocess the data in two different way for the SVR model analysis -  either normalize it or standardize it. I will start from analysing linear kernel followed by polynomial and RBF kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfI1Pg4IPci6"
   },
   "source": [
    "Starting from the linear SVR, I am using LinearSVR due to it being more efficient than the standard SVR from sklearn library. In addition, since the data has a higher number of observations than features, I set the algorithm to solve a primal optimization problem. Consequently, I opt for L2 loss. \n",
    "\n",
    "I first start with standardized data and then try normalized data (it is not centred around zero but in practice works well). The Linear SVR with non-preprocessed data did not converge even after adjusting the tolerance and maximum iterations, thus I will not be reporting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I57YdBJbPci7"
   },
   "outputs": [],
   "source": [
    "# getting standardized folds again\n",
    "train, train_labels, val, val_labels = Folds(features_scale, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0gpJOz1RPci8"
   },
   "outputs": [],
   "source": [
    "# setting the parameter space for linear kernel\n",
    "C_param = [0.1, 1, 10, 100, 1000]\n",
    "epsilon_param = [0.5, 1, 2]\n",
    "\n",
    "# empty lis to incorporate the mean values across all three folds.\n",
    "SVR_linear = []\n",
    "\n",
    "# Focus on linear kernel only. \n",
    "\n",
    "# loop over C parameter\n",
    "for c in C_param:\n",
    "    for e in epsilon_param:\n",
    "    # list to hold individual for RMSE values\n",
    "        RMSE_temp = []\n",
    "        # loop over the three folds defined above. \n",
    "        for i in range(0,3):\n",
    "            svr = LinearSVR(C = c, epsilon = e, dual = False, loss = 'squared_epsilon_insensitive')\n",
    "            svr.fit(train[i], train_labels[i])\n",
    "            # predict based on validation\n",
    "            pred = svr.predict(val[i])\n",
    "            # calculate RMSE of the validation fold\n",
    "            RMSE_temp.append(mean_squared_error(val_labels[i], pred, squared = False))\n",
    "        # take the average RMSE over all three validation folds.     \n",
    "        SVR_linear.append(np.mean(RMSE_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "9--BumKrPci9",
    "outputId": "e6a36da6-e344-45f2-901a-4f70ddad9e6c"
   },
   "outputs": [],
   "source": [
    "# Result for SVR with a linear kernel. \n",
    "SVR_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTvoCe7BPci_"
   },
   "outputs": [],
   "source": [
    "# getting normalized folds again\n",
    "train, train_labels, val, val_labels = Folds(features_norm, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BE9HQ9JMPcjD"
   },
   "outputs": [],
   "source": [
    "# setting the parameter space for linear kernel\n",
    "C_param = [0.1, 1, 10, 100 , 1000]\n",
    "epsilon_param = [0.5, 1, 2]\n",
    "\n",
    "# empty lis to incorporate the mean values across all three folds.\n",
    "SVR_linear = []\n",
    "\n",
    "# Focus on linear kernel only. \n",
    "\n",
    "# loop over C parameter\n",
    "for c in C_param:\n",
    "    for e in epsilon_param:\n",
    "    # list to hold individual for RMSE values\n",
    "        RMSE_temp = []\n",
    "        # loop over the three folds defined above. \n",
    "        for i in range(0,3):\n",
    "            svr = LinearSVR(C = c, epsilon = e, dual = False, loss = 'squared_epsilon_insensitive')\n",
    "            svr.fit(train[i], train_labels[i])\n",
    "            # predict based on validation\n",
    "            pred = svr.predict(val[i])\n",
    "            # calculate RMSE of the validation fold\n",
    "            RMSE_temp.append(mean_squared_error(val_labels[i], pred, squared = False))\n",
    "        # take the average RMSE over all three validation folds.     \n",
    "        SVR_linear.append(np.mean(RMSE_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "aZif5jtoPcjG",
    "outputId": "d3424b3f-13a6-435b-eb07-b25c781aa186"
   },
   "outputs": [],
   "source": [
    "SVR_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXVuyiQQPcjH"
   },
   "source": [
    "As expected, the standardized data works better in the linear SVR case. The lowest result of 2.851 with the standardized data was achieved with C = 1000 and epsilon 0.5. Normalized data, in turn, yielded the lowest score of 3.670. I will thus from now on focus on the standardized data only.\n",
    "\n",
    "Now, I will test the polynomial kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcZN-UY2PcjI"
   },
   "outputs": [],
   "source": [
    "# getting standardized folds again\n",
    "train, train_labels, val, val_labels = Folds(features_scale, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m9ecdra-PcjK"
   },
   "outputs": [],
   "source": [
    "# setting the parameter space for the polynomial SVR\n",
    "C_param = [ 0.01, 0.1, 1, 10, 100]\n",
    "degree_param = [2,3]\n",
    "epsilon_param = [0.5, 1, 2]\n",
    "\n",
    "# empty lis to incorporate the mean values across all three folds.\n",
    "SVR_poly = []\n",
    "\n",
    "# Focus on polynomial kernel\n",
    "\n",
    "# loop over the degrees of polynomial -  starting with 2 and 3\n",
    "for d in degree_param:\n",
    "    # loop over C parameter\n",
    "    for c in C_param:\n",
    "        # loop over epsilon\n",
    "        for e in epsilon_param:\n",
    "            # list to hold individual for RMSE values\n",
    "            RMSE_temp = []\n",
    "            for i in range(0,3):\n",
    "                svr = SVR(kernel = 'poly', degree = d, epsilon = e, C = c)\n",
    "                svr.fit(train[i], train_labels[i])\n",
    "                # predict based on validation\n",
    "                pred = svr.predict(val[i])\n",
    "                # calculate RMSE of the validation fold\n",
    "                RMSE_temp.append(mean_squared_error(val_labels[i], pred, squared = False))\n",
    "            # take the average RMSE over all three validation folds.       \n",
    "            SVR_poly.append(np.mean(RMSE_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "T8VZCcfzPcjM",
    "outputId": "c6824505-f849-4d07-a7ba-bfd41585fdf9"
   },
   "outputs": [],
   "source": [
    "# printing out the polynomial SVR results\n",
    "SVR_poly\n",
    "# degree = 2, C = 1 and epsilon = 2 gives RMSE of  3.0267288143717423,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kOJ-Z8i3PcjN"
   },
   "source": [
    "SVR with polynomial kernel achieved the lowest RMSE OF 3.025 with the polynomial degree of 2, C = 1 and epsilon 2. However, the linear SVR had achieved a better validation performance and so far remains a stronger candidate. \n",
    "\n",
    "I will now only have to examine the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTk7PfMDPcjN"
   },
   "outputs": [],
   "source": [
    "# Grid search with a focus on RBF kernel\n",
    "\n",
    "gamma_param = [ 1e-2, 1e-4, 1, 10]\n",
    "C_param = [ 0.01, 0.1, 1, 10, 100]\n",
    "epsilon_param = [0.5, 1, 2]\n",
    "\n",
    "# empty lis to incorporate the mean values across all three folds.\n",
    "SVR_rbf = []\n",
    "\n",
    "# Focus on RBF kernel\n",
    "\n",
    "# Loop over gamma parameter\n",
    "for g in gamma_param:\n",
    "    # loop over C parameter\n",
    "    for c in C_param:\n",
    "        # list to hold individual for RMSE values\n",
    "        for e in epsilon_param:\n",
    "            RMSE_temp = []\n",
    "            for i in range(0,3):\n",
    "                svr = SVR(kernel = 'rbf', gamma = g, epsilon = e, C = c)\n",
    "                svr.fit(train[i], train_labels[i]) \n",
    "                 # predict based on validation\n",
    "                pred = svr.predict(val[i])\n",
    "                # calculate RMSE of the validation fold\n",
    "                RMSE_temp.append(mean_squared_error(val_labels[i], pred, squared = False))\n",
    "            # take the average RMSE over all three validation folds.       \n",
    "            SVR_rbf.append(np.mean(RMSE_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ybNtzCFxPcjP",
    "outputId": "6ca81bdf-d453-4dce-f77e-892670c81f42"
   },
   "outputs": [],
   "source": [
    "# printing RBF kernel SVR results\n",
    "SVR_rbf\n",
    "# Lowest RMSE =  2.240149296447879,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qorVDMvEPcjQ"
   },
   "source": [
    "RBF kernel outperforms all the above SVR models. The lowest score of 2.240 was achieved with gamma = 0.01, C = 10 and epsilon = 0.5. This yields a  roughly 0.6 lower RMSE than with the linear kernel. I thus choose RBF with gamma = 0.01, C = 10 and epsilon = 0.5 to be my chosen model for the testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLFOibIAPcjQ"
   },
   "source": [
    "#### Testing SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H54DrbbQPcjR"
   },
   "outputs": [],
   "source": [
    "# defining the testing model \n",
    "svr = SVR(kernel = 'rbf', gamma = 0.01, C = 10, epsilon = 0.5).fit(features_scale, Y[:5841])\n",
    "\n",
    "# standardizing the testing data\n",
    "features_scale_test = scaler.fit_transform(features_test)\n",
    "\n",
    "svr_predict = svr.predict(features_scale_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W_NHLCmxPcjS",
    "outputId": "9942a0c6-cd8f-417f-9dff-d48f610dfbb7"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\", mean_squared_error(Y[5841:], svr_predict, squared = False),\n",
    "      \"MAE:\", mean_absolute_error(Y[5841:], svr_predict),\n",
    "      \"R2:\", r2_score(Y[5841:], svr_predict),\n",
    "      \"Correlation:\",np.corrcoef(Y[5841:], svr_predict)[0,1])\n",
    "# RMSE: 3.607931584126985 MAE: 1.942052130388768 R2: 0.5039871800491145 Correlation: 0.729540358418439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "wCUJqEZiV1Qs",
    "outputId": "ca127f53-7cc4-429b-aa78-80fd2908a0ae"
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y[5841:], (svr_predict - Y[5841:]))\n",
    "plt.title(\"True counts vs residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "InjMdNPGPcjT"
   },
   "source": [
    "SVR with RBF kernel performed better than the Ridge regression. RMSE fell by roughly 0.17, MAE by 0.896 R2 rose by roughly 4.5 percentage points, yet Correlation fell by 0.069. Yet, it still did not manage to outperform the MLP which stands as the best model considered so far. \n",
    "\n",
    "A summary table bellow allows a quick comparison of all the model discussed so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk1E93snPcjU"
   },
   "source": [
    "### Summary of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "iwdZkM0qPcjU",
    "outputId": "35ff3951-c77e-407f-9126-e285467e5d81"
   },
   "outputs": [],
   "source": [
    "data_summary = { \" \": [\"OLS\", \"MLP\", \"Ridge\", \"SVR\"],\n",
    "                    \"RMSE\": [mean_squared_error(Y[5841:], reg_predict_test, squared = False),\n",
    "                             np.mean(m3_test_summary[:,0]),\n",
    "                            mean_squared_error(Y[5841:], ridge_predict, squared = False),\n",
    "                            mean_squared_error(Y[5841:], svr_predict, squared = False)],\n",
    "                  \"MAE\": [mean_absolute_error(Y[5841:], reg_predict_test),\n",
    "                          np.mean(m3_test_summary[:,1]),\n",
    "                        mean_absolute_error(Y[5841:], ridge_predict), \n",
    "                        mean_absolute_error(Y[5841:], svr_predict)],\n",
    "                      \"R2\": [r2_score(Y[5841:], reg_predict_test),\n",
    "                              np.mean(m3_test_summary[:,2]),\n",
    "                            r2_score(Y[5841:], ridge_predict),\n",
    "                             r2_score(Y[5841:], svr_predict)],\n",
    "                     \"Correlation\": [np.corrcoef(Y[5841:], reg_predict_test)[0,1],\n",
    "                                     np.mean(m3_test_summary[:,3]),\n",
    "                                     np.corrcoef(Y[5841:], ridge_predict)[0,1],\n",
    "                                      np.corrcoef(Y[5841:], svr_predict)[0,1]],\n",
    "                      \n",
    "                     }\n",
    "\n",
    "model_summary = pd.DataFrame(data_summary, columns = [' ','RMSE','MAE','R2','Correlation'])\n",
    "\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WUqrCgcPcjV"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Avnq36G2fVK"
   },
   "source": [
    "The first task is to decide on the cross-validation technique. It would be ideal to use the same technique as in the Question 2, yet it will take a lot more time to do so. Thus, saving time, I have decided to use one fold validation instead. Consequently, I have decided to use the images from patients 1 to 10 (inclusive) for testing and patients 11 to 13 (inclusive) for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRS9R_PkfA1-"
   },
   "outputs": [],
   "source": [
    "# seeing again the unique counts so I can decide on splits\n",
    "np.unique(P, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgCk6ZhtPcjW"
   },
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "X_train = X[:3884,:,:,:].astype(np.float32)\n",
    "Y_train = Y[:3884].astype(np.float32)\n",
    "X_test = X[3884:5841,:,:,:].astype(np.float32)\n",
    "Y_test = Y[3884:5841].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJVDCzalTGtX"
   },
   "source": [
    "I have started from 2 convolutional layer and 2 hidden layers network all with ReLU activation function and batch size 32. Trying out various numbers of kernels and neurons, I have observed that the training model has achieved the best performance when the number of filters in the second convolutional layer is larger than in the first. However, even if the model was learning the training data very well (MSE dropped to around 1), it was overfitting so that the validation error would remain high. Thus, I proceeded with regularization. Beginning with L2 normalization did not improve the results a lot, this is, I suppose was the case due to the fact that we have rather large images and even the low constant of normalization forces the weights to decay too much. Following that, I have tried max-norm with dropout technique described to be working well in the Srivastava et al. (2014). However, this also did not bring satisfactory results. Lastly, I replaced max-norm constraint by the Batch Normalization. Increasing the drop-out rate to 30% alongside normalizing batches gave me the best results. However, the validation loss graph seemed to be very volatile. This obstructed from seeing the convergence. To solve this issue I increased the batch size to 64 and standardized the data. Unfortunately, whilst this partly solved the problem and the trend became less volatile, the minimum MSE loss achieved on validation was over 5 which is higher than what I have achieved before. Lastly, wanting to tune in my model better I have tried a linear activation function for the outer layer. Both, linear and ReLU activation functions on the outer layer seemed to yield similar results. Linear activation would show signs of convergence around 35th epoch and would yield validation RMSE of 1.8719385 whilst ReLU outer layer would converge around 45th epoch and yield RMSE of 1.868874. Thus, even though it is a marginal decline, I have chosen the model with the ReLU outer layer. The model is thus presented bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Iq-s6zgpfPaY",
    "outputId": "cdd8c2ac-ef6d-40a0-930f-36a0ea275f0b"
   },
   "outputs": [],
   "source": [
    "# Defining the final CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(18, kernel_size=(3, 3), activation='relu',  \n",
    "                 input_shape=(267,267,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),data_format=\"channels_last\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(36, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "model.compile(loss='MSE',optimizer='adam',metrics=['MAE'])\n",
    "\n",
    "# storing the model so could retain later.\n",
    "checkpoint_path = \"weights_final_cnn_relu.hdf5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "cp_model = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', save_weights_only= False,\n",
    "                              save_best_only=False, verbose=1, mode = \"min\")\n",
    "# early stopping so would not waste the time too much\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=40,\n",
    "    verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "\n",
    "history1 = model.fit(X_train, Y_train,\n",
    "                     validation_data= (X_test, Y_test), \n",
    "                     batch_size=64, epochs=100, callbacks = [early_stopping, cp_model], verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "1DZH01k2fVgA",
    "outputId": "d891ea36-5441-43d7-b436-6d4857667bbd"
   },
   "outputs": [],
   "source": [
    "# plotting training and validation MSE loss\n",
    "plt.plot(history1.history['loss'][:])\n",
    "plt.plot(history1.history['val_loss'][:])\n",
    "plt.title('model MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# convergence signs between 40 to 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "HGuMZeOtfdRa",
    "outputId": "ea52ee34-a86b-4e57-a453-f2fd8d9ae675"
   },
   "outputs": [],
   "source": [
    "# Plotting training and validation MAE loss\n",
    "plt.plot(history1.history['MAE'][:])\n",
    "plt.plot(history1.history['val_MAE'][:])\n",
    "plt.title('model MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# convergence signs between 40 and 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5pklDXK25OB5",
    "outputId": "52b4a000-bde7-4f0d-9b4a-ca764223f1e8"
   },
   "outputs": [],
   "source": [
    "# getting validation results with the best weights\n",
    "pred_relu = model.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\", mean_squared_error(Y_test, pred_relu, squared = False),\n",
    "      \"MAE:\", mean_absolute_error(Y_test, pred_relu),\n",
    "      \"R2:\", r2_score(Y_test, pred_relu),\n",
    "      \"Correlation:\", np.corrcoef(Y_test, np.reshape(pred_relu, (1, np.shape(pred_relu)[0])))[0,1])\n",
    "# 1.868874 1.1523674 0.8116560342960611 0.9009959414135418"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbxMCFRqAYbn"
   },
   "source": [
    "The validation performance is very good, better than any other model considered before. However, the validation weights were \"hand-picked\" here since I could see their loss whilst training. Now let's examine the performance on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "krrv0MxRxaKU"
   },
   "source": [
    "#### Testing CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JmHxDtS82X6R",
    "outputId": "e668663c-3b6a-412b-a900-98f53486ac4d"
   },
   "outputs": [],
   "source": [
    "# testing the model on unseen data\n",
    "input_shape = (267, 267, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(18, kernel_size=(3, 3), activation='relu',  \n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),data_format=\"channels_last\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(36, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format=\"channels_last\"))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(BatchNormalization(axis = -1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "model.compile(loss='MSE',optimizer='adam',metrics=['MAE'])\n",
    "\n",
    "checkpoint_path = \"weights_final_cnn_test.hdf5\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)  \n",
    "cp_model = ModelCheckpoint(checkpoint_path, monitor = 'loss',  \n",
    "                              save_best_only=False, verbose=1, mode = \"min\")\n",
    "\n",
    "history1 = model.fit(X[:5841,:,:,:].astype(np.float32), Y[:5841].astype(np.float32), \n",
    "                     batch_size=64, epochs=45, \n",
    "                     callbacks = [cp_model], verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "s07qUW2f5aXj",
    "outputId": "a3c85770-dd8f-4f46-b87b-05853752291f"
   },
   "outputs": [],
   "source": [
    "# plotting training loss curve\n",
    "plt.plot(history1.history['loss'][:])\n",
    "plt.title('model MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FngU83zzovtI",
    "outputId": "bdf1ec93-fd5f-4697-9099-0a69bb80e062"
   },
   "outputs": [],
   "source": [
    "# getting validation performace statistics\n",
    "model.load_weights(\"weights_final_cnn_test.hdf5\")\n",
    "pred_relu = model.predict(X[5841:,:,:,:].astype(np.float32))\n",
    "\n",
    "print(\"RMSE:\", mean_squared_error(Y[5841:].astype(np.float32), pred_relu, squared = False),\n",
    "      \"MAE:\",mean_absolute_error(Y[5841:].astype(np.float32), pred_relu),\n",
    "      \"R2:\",r2_score(Y[5841:].astype(np.float32), pred_relu),\n",
    "      \"Correlation:\", np.corrcoef(Y[5841:].astype(np.float32), np.reshape(pred_relu, (1, np.shape(pred_relu)[0])))[0,1])\n",
    "# 2.6366537 1.8547359 0.7350996790305697 0.8788127874874672\n",
    "# 2.653262 1.7509032 0.7317519530679418 0.8724536907598069\n",
    "# 3.5863793 2.185601 0.509895425576637 0.8444601093429096\n",
    "# 3.0134172 2.2493796 0.6539850318898193 0.8506449953651958\n",
    "# 3.5236025  2.448045  0.5269030788416225  0.8031634577696839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gr4VtFg1BRxd"
   },
   "outputs": [],
   "source": [
    "CNN_summary = np.array(\n",
    "[[2.6366537, 1.8547359, 0.7350996790305697, 0.8788127874874672],\n",
    "[2.653262, 1.7509032, 0.7317519530679418, 0.8724536907598069],\n",
    "[3.5863793, 2.185601, 0.509895425576637, 0.8444601093429096],\n",
    "[3.0134172, 2.2493796, 0.6539850318898193, 0.8506449953651958],\n",
    " [3.5236025,  2.448045,  0.5269030788416225,  0.8031634577696839]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "QpVdGcMbBluK",
    "outputId": "c015c88d-9666-4412-d021-245af0000fd3"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE:\", np.mean(CNN_summary[:,0]), \"MAE:\", np.mean(CNN_summary[:,1]), \n",
    "      \"R2:\", np.mean(CNN_summary[:,2]), \"Correlation\", np.mean(CNN_summary[:,3]))\n",
    "# RMSE: 3.0826629399999996 MAE: 2.09773294 R2: 0.6315270336813181 Correlation 0.8499070081450126\n",
    "\n",
    "print(\"RMSE variance:\", np.var(CNN_summary[:,0]), \"MAE variance:\", np.var(CNN_summary[:,1]), \n",
    "      \"R2 variance:\", np.var(CNN_summary[:,2]), \"Correlation variance:\", np.var(CNN_summary[:,3]))\n",
    "#RMSE variance: 0.1672524497702104 MAE variance: 0.06655489496719841 \n",
    "#R2 variance: 0.009403421806131901 Correlation variance: 0.0007118139619430679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "m_vHzkDclyOR",
    "outputId": "54ae0dbc-cacb-45d7-ef13-f3fef1040a1e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y[5841:], (np.reshape(pred_relu, (1, np.shape(pred_relu)[0])) - Y[5841:]))\n",
    "plt.title(\"CNN true vs residual scatterplot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xubaJp_CsBaV"
   },
   "source": [
    "The performance on testing data did not bring very good news. Whilst the two first times, CNN managed to yield RMSE of roughly 2.64, the third times it rose well over 3. Consequently, an average performance remains bellow that of Multilayer Perceptron. There can be several possible explanations, why this is the case. Firstly, it seems that the model is learning the training data well, yet it fails to generalize, thus I would need to further investigate regularization techniques. Secondly, it might be better to opt for a steadier model with standardized data since, at least, it seems to yield constant results over the validation set albeit the minimum score remains above that of the unprocessed data. Thirdly, it might be the case that the chosen validation set is \"easy\". From MLP we can see that if we keep the last third of the data as validation, the testing loss trend sometimes even goes bellow training. If the third set is really too easy, we would need to validate the model on a different set. \n",
    "\n",
    "Overall, CNN faces the same difficulties as the previous models. It struggles to recognise zero count data as well as underestimates the high counts. We can explore the feature maps and see what features the model was extracting and maybe understand where the problem of the neural network is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lI4uQY5xyzOD"
   },
   "source": [
    "#### Feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "vc2mQxEZzgDT",
    "outputId": "56dd63fb-acbe-4bb5-f8a6-198fd6714ecf"
   },
   "outputs": [],
   "source": [
    "# summarising the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "xP5xsuTF3vg2",
    "outputId": "b85c3227-30fd-43b6-8784-6355f1c78ee4"
   },
   "outputs": [],
   "source": [
    "# Choosing an arbitrary image for which feature maps will be generated\n",
    "plt.imshow(X[6000,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "colab_type": "code",
    "id": "qMnXC8TzPcje",
    "outputId": "15fbb825-3cce-4bf9-e5b9-963d317d1555"
   },
   "outputs": [],
   "source": [
    "# plotting the feature maps of the firs convolutional layer.\n",
    "model_1 = tf.compat.v1.keras.Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
    "\n",
    "# extracting the feature maps\n",
    "feature_maps = model_1.predict(np.reshape(X[6000,:,:,:], (1, 267, 267, 3)))\n",
    "\n",
    "# plot all 16 maps in a 3x6 grid\n",
    "\n",
    "ix = 1\n",
    "for _ in range(3):\n",
    "\tfor _ in range(6):\n",
    "\t\t# specify subplot and turn of axis\n",
    "\t\tax = plt.subplot(3, 6, ix)\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\t\t# plot filter channel in grayscale\n",
    "\t\tplt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    "\t\tix += 1\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "pXdBYATR9_Pe",
    "outputId": "949cf012-1aee-4a68-cf4d-35f5e0c9b96e"
   },
   "outputs": [],
   "source": [
    "model_2 = tf.compat.v1.keras.Model(inputs=model.inputs, outputs=model.layers[5].output)\n",
    "\n",
    "feature_maps_2 = model_2.predict(np.reshape(X[6000,:,:,:], (1, 267, 267, 3)))\n",
    "\n",
    "# plot all 36 maps in a 6x6 grid\n",
    "\n",
    "ix = 1\n",
    "for _ in range(6):\n",
    "\tfor _ in range(6):\n",
    "\t\t# specify subplot and turn of axis\n",
    "\t\tax = plt.subplot(6, 6, ix)\n",
    "\t\tax.set_xticks([])\n",
    "\t\tax.set_yticks([])\n",
    "\t\t# plot filter channel in grayscale\n",
    "\t\tplt.imshow(feature_maps_2[0, :, :, ix-1], cmap='gray')\n",
    "\t\tix += 1\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3flxDBOoz32b"
   },
   "source": [
    "From the feature maps, it seems that the convolutional kernels are learning to predict the data well. In the first batch of feature maps, we can see that it separates brown cells from the blue cells as well as manages to isolate cells from the background. The same can be seen from the second batch of feature maps. Thus, I am leaning towards the idea that the main issue with this CNN built is not the convolutional layers but the counting. It is therefore likely that if instead of MLP, I have tried some different architecture or even different machine learning techniques, I could have realised a fuller power of these convolutional layers. \n",
    "\n",
    "THE END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NKWMY_UF-qi5"
   },
   "source": [
    "*What now, José?\n",
    "The party’s over,\n",
    "the lights are off,\n",
    "the crowd’s gone,\n",
    "the night’s gone cold,\n",
    "what now, José?* - Carlos Drummond de Andrade "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5sYxVh66AqLn"
   },
   "source": [
    "**References**\n",
    "\n",
    "Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. and Salakhutdinov, R., 2014. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), pp.1929-1958."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Ass_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
